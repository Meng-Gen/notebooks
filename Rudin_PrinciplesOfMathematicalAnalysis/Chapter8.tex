\documentclass{article}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{mathrsfs}
\parindent=0pt

\def\upint{\mathchoice%
    {\mkern13mu\overline{\vphantom{\intop}\mkern7mu}\mkern-20mu}%
    {\mkern7mu\overline{\vphantom{\intop}\mkern7mu}\mkern-14mu}%
    {\mkern7mu\overline{\vphantom{\intop}\mkern7mu}\mkern-14mu}%
    {\mkern7mu\overline{\vphantom{\intop}\mkern7mu}\mkern-14mu}%
  \int}
\def\lowint{\mkern3mu\underline{\vphantom{\intop}\mkern7mu}\mkern-10mu\int}

\begin{document}

\textbf{\Large Chapter 8: Some Special Functions} \\\\



\emph{Author: Meng-Gen Tsai} \\
\emph{Email: plover@gmail.com} \\\\



% References:
% 1. http://math.ucsd.edu/~lni/math140/HW140B_7_solutions.pdf
% 2. http://www.math.ucsd.edu/~ibejenar/teaching/2019/140B/HW1S.pdf
% 3. https://minds.wisconsin.edu/bitstream/handle/1793/67009/rudin%20ch%208.pdf?sequence=4
% 4. https://math.mit.edu/~gs/cse/websections/cse41.pdf



\textbf{Supplement.} Fourier coefficients in Definition 8.9.
\begin{enumerate}
\item[(1)]
Write $$f(x) = a_0 + \sum_{n = 1}^{N}(a_n \cos(nx) + b_n \sin(nx)),
x \in \mathbb{R}$$
(as the textbook Rudin, Principles of Mathematical Analysis, Third Edition).
Then
\begin{align*}
a_0 &= \frac{1}{2 \pi} \int_{-\pi}^\pi f(x) dx. \\
a_n &= \frac{1}{\pi} \int_{-\pi}^\pi f(x) \cos(nx) dx, n \in \mathbb{Z}^+. \\
b_n &= \frac{1}{\pi} \int_{-\pi}^\pi f(x) \sin(nx) dx, n \in \mathbb{Z}^+.
\end{align*}

\item[(2)]
One might write in one different form,
$$f(x) = \frac{a_0}{2} + \sum_{n = 1}^{N}(a_n \cos(nx) + b_n \sin(nx)),
x \in \mathbb{R}.$$
The only difference between the new one and the old one is $a_0$,
so $a_0$ should be
$$a_0 = \frac{1}{\pi} \int_{-\pi}^\pi f(x) dx.$$

\item[(3)]
Again, one might write in one different form,
$$f(x) = \frac{a_0}{\sqrt{2}} + \sum_{n = 1}^{N}(a_n \cos(nx) + b_n \sin(nx)),
x \in \mathbb{R}.$$ Similarly, $a_0$ should be
$$a_0 = \frac{1}{\pi} \int_{-\pi}^\pi \frac{f(x)}{\sqrt{2}} dx.$$

\item[(4)]
Recall $f(x) = \sum_{-N}^{N} c_n e^{inx}$ ($x \in \mathbb{R}$) where
$$c_n = \frac{1}{2 \pi} \int_{-\pi}^\pi f(x) e^{-inx} dx.$$
The relations among $a_n$, $b_n$ of this textbook and $c_n$ are
\begin{align*}
c_0 &= a_0 \\
c_n &= \frac{1}{2} \left( a_n + i b_n \right), n \in \mathbb{Z}^+. \\
\end{align*}
\end{enumerate}



\textbf{Supplement.} Parseval's theorem 8.16.
\begin{enumerate}
\item[(1)]
Given $$f(x) = a_0 + \sum_{n = 1}^{\infty}(a_n \cos(nx) + b_n \sin(nx)),
x \in \mathbb{R}.$$
Then
$$\frac{1}{\pi} \int_{-\pi}^\pi |f(x)|^2 dx
= 2 a_0^2 + \sum_{n = 1}^{\infty}(a_n^2 + b_n^2).$$
\item[(2)]
Given $$f(x) = \frac{a_0}{2} + \sum_{n = 1}^{\infty}(a_n \cos(nx) + b_n \sin(nx)),
x \in \mathbb{R}.$$
Then
$$\frac{1}{\pi} \int_{-\pi}^\pi |f(x)|^2 dx
= \frac{a_0^2}{2} + \sum_{n = 1}^{\infty}(a_n^2 + b_n^2).$$
\item[(3)]
Given $$f(x) = \frac{a_0}{\sqrt{2}} + \sum_{n = 1}^{\infty}(a_n \cos(nx) + b_n \sin(nx)),
x \in \mathbb{R}.$$
Then
$$\frac{1}{\pi} \int_{-\pi}^\pi |f(x)|^2 dx
= a_0^2 + \sum_{n = 1}^{\infty}(a_n^2 + b_n^2).$$ \\
\end{enumerate}



\textbf{Exercise 8.1.}
\emph{Define
\begin{equation*}
  f(x) =
    \begin{cases}
      e^{-\frac{1}{x^2}} & (x \neq 0), \\
      0                  & (x = 0).
    \end{cases}
\end{equation*}
Prove that $f$ has derivatives of all orders at $x = 0$,
and that $f^{(n)}(0) = 0$ for $n = 1, 2, 3, ...$} \\

$f(x)$ is an example of non-analytic smooth function, that is,
infinitely differentiable functions are not necessarily analytic.
In this exercise, we will show that Taylor series of $f$ at the origin
converges everywhere to the zero function.
So the Taylor series does not equal $f(x)$ for $x \neq 0$.
Consequently, $f$ is not analytic at $x = 0$. \\

\textbf{Claim 1.}
\emph{$$\lim_{x \rightarrow 0} g(x) e^{-\frac{1}{x^2}} = 0$$
for any rational function $g(x) \in \mathbb{R}(x)$.} \\

\emph{Proof.}
Write $g(x) = \frac{p(x)}{q(x)}$ for some $p(x), q(x) \in \mathbb{R}[x].$
Write $q(x) = b_m x^m + b_{m - 1} x^{m - 1} + \cdots + b_0$.
$q(x)$ is not identically zero, that is, there exists the unique coefficient
of the least power of $x$ in $q(x)$ which is non-zero, say $b_M \neq 0$.
Now write $g(x)$ as $g(x) = \frac{p(x)/x^M}{q(x)/x^M}$.
The denominator of $g(x)$ tends to $b_M \neq 0$ as $x \rightarrow 0$.
By the similar argument of Theorem 8.6(f)
($\lim_{x \rightarrow \infty} x^n e^{-x} = 0$ for any $n \in \mathbb{Z}$),
$$\frac{p(x)}{x^M} e^{-\frac{1}{x^2}} \rightarrow 0 \text{ as } x \rightarrow 0.$$
Hence, $\lim_{x \rightarrow 0} g(x) e^{-\frac{1}{x^2}} = 0$
for any $g(x) \in \mathbb{R}(x)$.
$\Box$ \\

\textbf{Claim 2.}
\emph{Given any real $x \neq 0$
$$f^{(n)}(x) = g_n(x) e^{-\frac{1}{x^2}}$$
for some rational function $g(x) \in \mathbb{R}(x)$.} \\

\emph{Proof.}
Say $g_0(x) = 1 \in \mathbb{R}(x)$.
Notice that $\mathbb{R}(x)$ is a field and
$g'(x) \in \mathbb{R}(x)$ for any $g(x) \in \mathbb{R}(x)$.
(Write $g(x) = \frac{p(x)}{q(x)}$ for some $p(x), q(x) \in \mathbb{R}[x]$.
Notice that $p'(x) \in \mathbb{R}[x]$ for any $p(x) \in \mathbb{R}[x]$.)
Now we prove by mathematical induction.
For $n = 1$, we have
\begin{align*}
f'(x)
&= g_0'(x) e^{-\frac{1}{x^2}}
+ g_0(x) \cdot \left( -\frac{1}{x^2} \right)' e^{-\frac{1}{x^2}} \\
&= \left( g_0'(x) + g_0(x) \cdot \left( -\frac{1}{x^2} \right)' \right) e^{-\frac{1}{x^2}} \\
&= g_1(x) e^{-\frac{1}{x^2}}
\end{align*}
where $g_1(x) = g_0'(x) + g_0(x) \cdot (-\frac{1}{x^2})' \in \mathbb{R}(x)$.
Now assume $n = k$ holds.
For $n = k + 1$, similar to $n = 1$,
$f^{(k + 1)}(x) = g_{k + 1}(x) e^{-\frac{1}{x^2}}$
where $g_{k + 1}(x) = g_k'(x) + g_k(x) \cdot (-\frac{1}{x^2})' \in \mathbb{R}(x)$.
$\Box$ \\

\emph{Proof of Exercise 8.1.}
Prove by mathematical induction.
For $n = 1$,
$$f'(0) = \lim_{t \rightarrow 0} \frac{e^{- \frac{1}{t^2}} - 0}{t} = 0.$$
(Use Claim 1.)
Now assume $n = k$ holds.
For $n = k + 1$,
$$f^{(k + 1)}(0)
= \lim_{t \rightarrow 0} \frac{f^{(k)}(t) - f^{(k)}(0)}{t}
= \lim_{t \rightarrow 0} \frac{g_k(t) e^{- \frac{1}{t^2}} - 0}{t} = 0.$$
(Use Claim 1 and 2.)
Thus, $f^{(n)}(0) = 0$ for $n \in \mathbb{Z}^+$.
$\Box$ \\\\



\textbf{Exercise 8.6.}
\emph{Suppose $f(x)f(y) = f(x + y)$ for all real $x$ and $y$. \\
(a) Assuming that $f$ is differentiable and not zero, prove that
$$f(x) = e^{cx}$$
where $c$ is a constant. \\
(b) Prove the same thing, assuming only that $f$ is continuous.} \\

(b) implies (a). We prove (b) directly. \\

\emph{Proof of (b).}
Since $f(x)$ is not zero, there exists $x_0 \in \mathbb{R}$ such that $f(x_0) \neq 0$.
So $f(0)f(x_0) = f(x_0)$, or $f(0) = 1$ by cancelling $f(x_0) \neq 0$. \\

Next, $f(\frac{n}{m}) = f(\frac{1}{m})^n$ for $m \in \mathbb{Z}$, $n \in \mathbb{Z}^{+}$.
Since $f$ is continuous at $x = 0$, $f$ is positive in the neighborhood of $x = 0$.
That is, there exists $N \in \mathbb{Z}^{+}$ such that $f(\frac{1}{m}) > 0$
whenever $|m| \geq N$.
So, $f(\frac{n}{m}) = f(\frac{1}{m})^n > 0$.
(Since $f(\frac{n}{m}) = f(\frac{kn}{km})$ for any $k \in \mathbb{Z}^{+}$,
we can rescale $m$ to $km$ such that $|km| \geq N$.)
That is, $f$ is positive on $\mathbb{Q}$.
Since $\mathbb{Q}$ is dense in $\mathbb{R}$ and $f$ is continuous on $\mathbb{R}$,
$f$ is positive on $\mathbb{R}$. \\

Now let $c = \log f(1)$ (which is well-defined since $f > 0$).
We write $f(1)$ in the two ways.
Firstly, $f(1) = f(\frac{n}{n}) = f(\frac{1}{n})^n$ where $n \in \mathbb{Z}^{+}$.
Secondly, $f(1) = e^c = (e^{\frac{c}{n}})^n$.
Since the positive $n$-th root is unique (Theorem 1.21),
$f(\frac{1}{n}) = e^{\frac{c}{n}}$ for $n \in \mathbb{Z}^{+}$.
By $f(x)f(-x) = f(0) = 1$ or $f(-x) = \frac{1}{f(x)}$,
$f(-\frac{1}{n}) = \frac{1}{e^{\frac{c}{n}}} = e^{-\frac{c}{n}}$ for $n \in \mathbb{Z}^{+}$.
Therefore,
$$f\left( \frac{1}{m} \right) = e^{\frac{c}{m}} \text{ where } m \in \mathbb{Z}.$$

By using
$f(\frac{n}{m}) = f(\frac{1}{m})^n$ for $m \in \mathbb{Z}$, $n \in \mathbb{Z}^{+}$ again,
$f(\frac{n}{m}) = e^{c \frac{n}{m}}$ where $m \in \mathbb{Z}, n \in \mathbb{Z}^{+}$, or
$$f(x) = e^{cx} \text{ where } x \in \mathbb{Q}.$$
Since $g(x) = f(x) - e^{cx}$ vanishes on a dense set of $\mathbb{Q}$
and $g$ is continuous on $\mathbb{R}$, $g$ vanishes on $\mathbb{R}$.
Therefore, $f(x) = e^{cx}$ for $x \in \mathbb{R}$.
$\Box$ \\



\textbf{Supplement.} Proof of (a).

\emph{Proof of (a).}
Since $f(x)$ is not zero, there exists $x_0 \in \mathbb{R}$ such that $f(x_0) \neq 0$.
So $f(0)f(x_0) = f(x_0)$, or $f(0) = 1$ by cancelling $f(x_0) \neq 0$. \\

Since $f$ is differentiable, for any $x \in \mathbb{R}$,
\begin{align*}
f'(x)
=& \lim_{h \rightarrow 0} \frac{f(x + h) - f(x)}{h} \\
=& \lim_{h \rightarrow 0} \frac{f(x)f(h) - f(x)}{h} \\
=& f(x) \lim_{h \rightarrow 0} \frac{f(h) - 1}{h} \\
=& f(x) \lim_{h \rightarrow 0} \frac{f(h) - f(0)}{h} \\
=& f(x) f'(0).
\end{align*}
Let $c = f'(0)$ be a constant. Then $f'(x) = c f(x)$. So $f(x) = e^{cx}$ for $x \in \mathbb{R}$.
(To see this, let $g(x) = \frac{f(x)}{e^{cx}}$ be well-defined on $\mathbb{R}$. $g(0) = 1$.
$g'(x) = 0$ since $f'(x) = c f(x)$. So $g(x)$ is a constant, or $g(x) = 1$ since $g(0) = 1$.
Therefore, $f(x) = e^{cx}$ on $\mathbb{R}$.)
$\Box$ \\



\textbf{Supplement.} Cauchy's functional equation.
\begin{enumerate}
\item[(1)]
\emph{(Cauchy's functional equation.) Suppose $f(x) + f(y) = f(x + y)$ for all real $x$ and $y$.
Assuming that $f$ is continuous, prove that $f(x) = cx$ where $c$ is a constant}. \\

Notice that we cannot let $g(x) = \log f(x)$
and apply Cauchy's functional equation on $g(x)$
to prove Exercise 8.6 since $f(x)$ is not necessary positive and thus
$g(x) = \log f(x)$ might be meaningless.
However, this wrong approach gives you some useful ideas such as
you need to prove that $f(x)$ is positive first,
and $f(x)$ should be equal to $e^{cx}$ where $c = g(1) = \log f(1)$.

\item[(2)]
\emph{Suppose $f(xy) = f(x) + f(y)$ for all positive real $x$ and $y$.
Assuming that $f$ is continuous, prove that $f(x) = c \log x$ where $c$ is a constant}.

\item[(3)]
\emph{Suppose $f(xy) = f(x)f(y)$ for all positive real $x$ and $y$.
Assuming that $f$ is continuous and positive,
prove that $f(x) = x^c$ where $c$ is a constant}.

\item[(4)]
\emph{Suppose $f(x + y) = f(x) + f(y) + xy$ for all real $x$ and $y$.
Assuming that $f$ is continuous,
prove that $f(x) = \frac{1}{2}x^2 + cx$ where $c$ is a constant}.

\item[(5)]
\emph{(USA 2002.) Suppose $f(x^2 - y^2) = x f(x) - y f(y)$ for all real $x$ and $y$.
Assuming that $f$ is continuous,
prove that $f(x) = cx$ where $c$ is a constant}. \\\\
\end{enumerate}



\textbf{Exercise 8.10.}
\emph{Prove that $\sum \frac{1}{p}$ diverges; the sum extends over all primes.} \\

There are many proofs of this result. We provide some of them. \\

\emph{Proof (Due to hint).}
Given $N$. \\
\textbf{Claim 1.}
\emph{Show that $\sum_{n \leq N} \frac{1}{n}
\leq \prod_{p \leq N} \left( 1 - \frac{1}{p} \right)^{-1}$.} \\
\emph{Proof of Claim 1.}
By the unique factorization theorem on $n \leq N$,
$$\sum_{n \leq N} \frac{1}{n}
\leq \prod_{p \leq N} \left( 1 + \frac{1}{p} + \frac{1}{p^2} + \cdots \right)
= \prod_{p \leq N} \left( 1 - \frac{1}{p} \right)^{-1}.$$
$\Box$ \\

By Claim 1 and the fact that $\sum \frac{1}{n}$ diverges,
there are infinitely many primes. \\

\textbf{Claim 2.}
\emph{Show that
$\prod_{p \leq N} \left( 1 - \frac{1}{p} \right)^{-1}
\leq \exp \left( \sum_{p \leq N} \frac{2}{p} \right).$} \\
\emph{Proof of Claim 2.}
By applying the inequality $(1 - x)^{-1} < e^{2x}$ where $x \in (0, \frac{1}{2}]$
on any prime $p$,
$$\left( 1 - \frac{1}{p} \right)^{-1} < \exp \left( \frac{2}{p} \right).$$
Now multiplying the inequality over all primes $p \leq N$ and noticing that
$\exp(x) \cdot \exp(y) = \exp(x + y)$, we have
$$\prod_{p \leq N} \left( 1 - \frac{1}{p} \right)^{-1}
\leq \exp \left( \sum_{p \leq N} \frac{2}{p} \right).$$
$\Box$ \\

By Claim 1 and Claim 2,
$$\sum_{n \leq N} \frac{1}{n}
\leq \exp \left( \sum_{p \leq N} \frac{2}{p} \right).$$
Since $\sum_{n \leq N} \frac{1}{n}$ diverges, the result holds.
$\Box$ \\



\emph{Proof (Due to Kenneth Ireland and Michael Rosen).}
The proof in Kenneth Ireland and Michael Rosen,
A Classical Introduction to Modern Number Theory, Second Edition (Theorem 3 in Chapter 2)
does not use the inequality $(1 - x)^{-1} < e^{2x}$ ($x \in (0, \frac{1}{2}]$) directly.
Instead, the authors take the logarithm on $(1 - p^{-1})^{-1}$ and estimate it.
(So the length of proof is longer than the proof due to hint.)
That is,
\begin{align*}
- \log(1 - p^{-1})
&= \sum_{n = 1}^{\infty} \frac{p^{-n}}{n} \\
&= \frac{1}{p} + \sum_{n = 2}^{\infty} \frac{p^{-n}}{n} \\
&< \frac{1}{p} + \sum_{n = 2}^{\infty} p^{-n} \\
&= \frac{1}{p} + \frac{p^{-2}}{1 - p^{-1}} \\
&< \frac{1}{p} + 2 \cdot \frac{1}{p^2}.
\end{align*}
Now we sum over all primes $p \leq N$,
$$\log \left( \prod_{p \leq N} \left( 1 - \frac{1}{p} \right)^{-1} \right)
< \sum_{p \leq N} \frac{1}{p} + 2 \sum_{p \leq N} \frac{1}{p^2}.$$
So
$$\log \sum_{n \leq N} \frac{1}{n}
< \sum_{p \leq N} \frac{1}{p} + 2 \sum_{p \leq N} \frac{1}{p^2}.$$
Notice that $\sum \frac{1}{n}$ diverges and $\sum \frac{1}{p^2}$ converges
(since $\sum \frac{1}{n^2}$ converges).
Therefore, $\sum \frac{1}{p}$ diverges.
$\Box$ \\



\emph{Proof (Due to I. Niven).}
It is an exercise in Kenneth Ireland and Michael Rosen,
A Classical Introduction to Modern Number Theory, Second Edition. See Exercise 27 in Chapter 2. \\

\textbf{Claim 1.}
\emph{Show that ${\sum}' \frac{1}{n}$, the sum being over square free integers, diverges.} \\
\emph{Proof of Claim 1.}
For any positive integers $n$, we can write $n = a^2 b$ where $a \in \mathbb{Z}^+$ and
$b$ is a square free integer.
Given $N$,
$$\sum_{n \leq N} \frac{1}{n}
\leq \left(\sum_{a = 1}^{\infty} \frac{1}{a^2} \right)
\left( {\sum_{b \leq N}}' \frac{1}{b} \right).$$
Notices that $\sum_{a = 1}^{\infty} \frac{1}{a^2}$ converges.
Since $\sum_{n \leq N} \frac{1}{n} \rightarrow \infty$ as $N \rightarrow \infty$,
$\sum'_{b \leq N}\frac{1}{b} \rightarrow \infty$ as $N \rightarrow \infty$.
$\Box$ \\

\textbf{Claim 2.}
\emph{Show that
$\prod_{p \leq N} ( 1 + \frac{1}{p} ) \rightarrow \infty$ as $N \rightarrow \infty$.} \\
\emph{Proof of Claim 2.}
By the unique factorization theorem on $n \leq N$,
$$\prod_{p \leq N} \left( 1 + \frac{1}{p} \right)
\geq {\sum_{n \leq N}}' \frac{1}{n}.$$
Since ${\sum_{n \leq N}}' \frac{1}{n} \rightarrow \infty$ as $N \rightarrow \infty$ (Claim 1),
the conclusion is established.
$\Box$ \\

By applying the inequality $e^x > 1 + x$ on any prime $p$,
$$\exp\left(\frac{1}{p}\right) > 1 + \frac{1}{p}.$$
Now multiplying the inequality over all primes $p \leq N$ and noticing that
$\exp(x) \cdot \exp(y) = \exp(x + y)$, we have
$$\exp\left(\sum_{p \leq N} \frac{1}{p} \right)
> \prod_{p \leq N} \left( 1 + \frac{1}{p} \right).$$
By Claim 2,
$\exp\left(\sum_{p \leq N} \frac{1}{p} \right) \rightarrow \infty$ as $N \rightarrow \infty$, or
$\sum_{p \leq N} \frac{1}{p} \rightarrow \infty$ as $N \rightarrow \infty$.
$\Box$ \\\\



\textbf{Exercise 8.12.}
\emph{Suppose $0 < \delta < \pi$,
\begin{equation*}
  f(x) =
    \begin{cases}
      1 & \text{ if } |x| \leq \delta, \\
      0 & \text{ if } \delta < |x| \leq \pi,
    \end{cases}
\end{equation*}
and $f(x + 2\pi) = f(x)$ for all $x$.}

\emph{(a) Compute the Fourier coefficients of $f$.}

\emph{(b) Compute that
$$\sum_{n = 1}^{\infty} \frac{\sin(n\delta)}{n} = \frac{\pi - \delta}{2}
\:\:\:\:\:\:\:\:
(0 < \delta < \pi).$$}

\emph{(c) Deduce from Parseval's theorem that
$$\sum_{n = 1}^{\infty} \frac{(\sin(n\delta))^2}{n^2 \delta} = \frac{\pi - \delta}{2}.$$}

\emph{(d) Let $\delta \rightarrow 0$ and prove that
$$\int_{0}^{\infty} \left( \frac{\sin x}{x} \right)^2 dx
= \frac{\pi}{2}.$$}

\emph{(e) Put $\delta = \frac{\pi}{2}$ in (c). What do you get?} \\

It is a centered square pulse around $x = 0$ with shift $\delta$.
Besides, $f(x)$ is an even function. \\

\emph{Proof of (a).}
\begin{align*}
c_0
&= \frac{1}{2 \pi} \int_{-\pi}^\pi f(x) dx \\
&= \frac{1}{2 \pi} \int_{-\delta}^\delta dx \\
&= \frac{\delta}{\pi}.
\end{align*}
For $0 \neq n \in \mathbb{Z}$,
\begin{align*}
c_n
&= \frac{1}{2 \pi} \int_{-\pi}^\pi f(x) e^{-inx} dx \\
&= \frac{1}{2 \pi} \int_{-\delta}^\delta e^{-inx} dx \\
&= \frac{1}{2 \pi} \cdot \frac{2 \sin(n \delta)}{n} \\
&= \frac{\sin(n \delta)}{n \pi}.
\end{align*}
$\Box$ \\

\textbf{Supplement.} Find $a_n$ and $b_n$ of this textbook. \\
By (a), $a_0 = \frac{\delta}{\pi}$,
$a_n = \frac{2 \sin(n \delta)}{n \pi}$, $b_n = 0$ for $n \in \mathbb{Z}^+$.
Surely, we can compute $a_n$ and $b_n$ ($n > 0$) directly.
Since $f(x)$ is an even function, $b_n = 0$.
And
\begin{align*}
a_n
&= \frac{1}{\pi} \int_{-\pi}^\pi f(x) \cos(nx) dx \\
&= \frac{2}{\pi} \int_{0}^\delta \cos(nx) dx \\
&= \frac{2 \sin(n \delta)}{n \pi}.
\end{align*}

\emph{Proof of (b).}
Given $x = 0$, there are constants $\delta' = \delta > 0$ and $M = 1 < \infty$ such that
$$|f(0 + t) - f(0)| \leq M|t|$$ for all $t \in (-\delta', \delta')$.
By Theorem 8.14,
$$\sum_{-\infty}^{\infty} c_n = f(0).$$
Notice that $c_{-n} = c_n$ for $n \in \mathbb{Z}^+$, so
\begin{align*}
\frac{\delta}{\pi} + 2 \sum_{n = 1}^{\infty} \frac{\sin(n \delta)}{n \pi}
&= 1 \\
\sum_{n = 1}^{\infty} \frac{\sin(n \delta)}{n}
&= \frac{\pi - \delta}{2}.
\end{align*}
$\Box$ \\

We can also use the expression $a_n$ and $b_n$ to prove the same thing.
Besides, taking $\delta = 1$ yields
$$\sum_{n = 1}^{\infty} \frac{\sin n}{n} = \frac{\pi - 1}{2}.$$ \\

\emph{Proof of (c).}
Since $f(x)$ is a Riemann-integrable function with period $2 \pi$,
by Parseval's theorem
$$\frac{1}{2 \pi} \int_{-\pi}^\pi |f(x)|^2 dx = \sum_{-\infty}^{\infty} |c_n|^2.$$
So
$$\frac{\delta}{\pi}
= \frac{\delta^2}{\pi^2} + 2 \sum_{n = 1}^{\infty} \frac{(\sin(n\delta))^2}{n^2 \pi^2}, $$
or
$$\sum_{n = 1}^{\infty} \frac{(\sin(n\delta))^2}{n^2 \delta}
= \frac{\pi - \delta}{2}.$$
$\Box$ \\

Notices that
$$\sum_{n = 1}^{\infty} \frac{(\sin n)^2}{n^2} = \frac{\pi - 1}{2}$$
as $\delta = 1$. \\

\emph{Proof of (d).}
TODO.
$\Box$ \\

\emph{Proof of (e).}
$$\sum_{n = 1}^{\infty} \frac{1}{(2n - 1)^2} = \frac{\pi^2}{8}.$$
Write
\begin{align*}
\sum_{n = 1}^{\infty} \frac{1}{n^2}
&= \sum_{n = 1}^{\infty} \frac{1}{(2n - 1)^2} + \sum_{n = 1}^{\infty} \frac{1}{(2n)^2} \\
&= \sum_{n = 1}^{\infty} \frac{1}{(2n - 1)^2} + \frac{1}{4} \sum_{n = 1}^{\infty} \frac{1}{n^2},
\end{align*}
so
$$\sum_{n = 1}^{\infty} \frac{1}{n^2}
= \frac{4}{3} \sum_{n = 1}^{\infty} \frac{1}{(2n - 1)^2}
= \frac{\pi^2}{6}.$$
$\Box$ \\\\



\textbf{Exercise 8.13.}
\emph{Put $f(x) = x$ if $0 \leq x < 2 \pi$, and apply Parseval's theorem to conclude that
$$\sum_{n = 1}^{\infty} \frac{1}{n^2} = \frac{\pi}{6}.$$}
\emph{Proof.}
\begin{align*}
c_0
&= \frac{1}{2 \pi} \int_{0}^{2 \pi} x dx \\
&= \pi,
\end{align*}
For $n \neq 0$,
\begin{align*}
c_n
&= \frac{1}{2 \pi} \int_{0}^{2 \pi} x e^{-inx} dx \\
&= \frac{1}{2 \pi} \left(
\left[ - \frac{1}{i n} x e^{-inx} \right]_{x = 0}^{x = 2 \pi}
- \int_{0}^{2 \pi} - \frac{1}{i n} e^{-inx} dx \right) \\
&= \frac{i}{n}.
\end{align*}
Since $f(x)$ is a Riemann-integrable function with period $2 \pi$,
by Parseval's theorem
$$\frac{1}{2 \pi} \int_{-\pi}^\pi |f(x)|^2 dx = \sum_{-\infty}^{\infty} |c_n|^2.$$
So
$$\frac{1}{2 \pi} \cdot \frac{(2 \pi)^3}{3}
= \pi^2 + 2 \sum_{n = 1}^{\infty} \frac{1}{n^2}, $$
or
$$\sum_{n = 1}^{\infty} \frac{1}{n^2}
= \frac{\pi^2}{6}.$$
$\Box$ \\\\

\textbf{Supplement.} \emph{
Put $f(x) = x^k$ if $k \in \mathbb{Z}^+$ and $0 \leq x < 2 \pi$.
Might show that
$$\sum_{n = 1}^{\infty} \frac{1}{n^{2k}} = r_k \pi^{2k}, r_k \in \mathbb{Q}.$$}

\end{document}