\documentclass{article}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage[none]{hyphenat}
\usepackage{mathrsfs}
\usepackage{physics}
\parindent=0pt

\def\upint{\mathchoice%
    {\mkern13mu\overline{\vphantom{\intop}\mkern7mu}\mkern-20mu}%
    {\mkern7mu\overline{\vphantom{\intop}\mkern7mu}\mkern-14mu}%
    {\mkern7mu\overline{\vphantom{\intop}\mkern7mu}\mkern-14mu}%
    {\mkern7mu\overline{\vphantom{\intop}\mkern7mu}\mkern-14mu}%
  \int}
\def\lowint{\mkern3mu\underline{\vphantom{\intop}\mkern7mu}\mkern-10mu\int}

\begin{document}



\textbf{\Large Chapter 6: The Riemann-Stieltjes Integral} \\\\



\emph{Author: Meng-Gen Tsai} \\
\emph{Email: plover@gmail.com} \\\\



% https://carma.newcastle.edu.au/resources/jon/Preprints/Books/CUP/CUPold/np-convex.pdf
% https://www.math.mcgill.ca/gantumur/math249w15/assignment3sol.pdf



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\textbf{Supplement.} Another definition of Riemann-Stieltjes integral.
\emph{(Exercise 7.3, 7.4 of the book
T. M. Apostol, Mathematical Analysis, Second Edition.)
Let $P$ be a partition of $[a, b]$.
The norm of a partition $P$ is the length of the largest subinterval $[x_{i-1}, x_i]$
of $P$ and is denoted by $\Vert P \Vert$.} \\

\emph{We say $f \in \mathscr{R}(\alpha)$
if there exists $A \in \mathbb{R}$ having the property that
for any $\varepsilon > 0$, there exists $\delta > 0$ such that
for any partition $P$ of $[a, b]$ with norm $\Vert P \Vert < \delta$
and for any choice of $t_i \in [x_{i-1}, x_i]$,
we have $|\sum_{i = 1}^{n} f(t_i) \Delta \alpha_i - A| < \varepsilon$.} \\\\

\textbf{Claim.}
\emph{$f \in \mathscr{R}$ in the sense of Definition 6.2
implies that
$f \in \mathscr{R}$ in the sense of this another definition.} \\

\emph{Proof of Claim.}
Let $A = \int f dx$, $M > 0$ be one upper bound of $|f|$ on $[a, b]$.
Given $\varepsilon > 0$, there exists a partition
$P_0 = \{a = x_0, x_1, \ldots, x_{N-1}, x_N = b \}$
such that
$U(P_0, f) \leq A + \frac{\varepsilon}{2}$.
Let $\delta = \frac{\varepsilon}{2MN} > 0$.
Then for any partition $P$ with norm $\Vert P \Vert < \delta$, write
$$U(P, f) = \sum_{i = 1}^{n} M_i \Delta x_i = S_1 + S_2,$$
where
$S_1$ is the sum of terms arising from those subintervals of $P$ containing no point of $P_0$,
$S_2$ is the sum of the remaining terms.
Then
\begin{align*}
S_1 &\leq U(P_0, f) < A + \frac{\varepsilon}{2}, \\
S_2 &\leq NM \Vert P \Vert < NM \delta < \frac{\varepsilon}{2}.
\end{align*}
Therefore, $U(P, f) < A + \varepsilon$.
Similarly, $L(P, f) > A - \varepsilon$ whenever $\Vert P \Vert < \delta'$.
Hence, $|\sum_{i = 1}^{n} f(t_i) \Delta x_i - A| < \varepsilon$
whenever $\Vert P \Vert < \min\{\delta, \delta'\}$.
(Copy Apostol's hint and ensure $M > 0$. $M$ in Apostol's hint might be zero if $f = 0$.)
$\Box$ \\



This supplement will be used in computing
$\int_0^{\infty} (\frac{\sin x}{x})^2 dx = \frac{\pi}{2}$ in Exercise 8.12. \\\\



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\textbf{Exercise 6.1.}
\emph{Suppose $\alpha$ increases on $[a, b]$, $a \leq â‰¤ x_0 \leq b$,
$\alpha$ is continuous at $x_0$, $f(x_0) = 1$, and $f(x) = 0$ if $x \neq x_0$.
Prove that $f \in \mathscr{R}(\alpha)$ and that $\int f d \alpha = 0$.} \\

Given any partition $P = \{a = p_0, p_1, \ldots, p_{n-1}, p_n = b \}$,
where $a = p_0 \leq p_1 \leq \cdots \leq p_{n-1} \leq p_n = b$.
We might compute $L(P, f, \alpha)$ and $U(P, f, \alpha)$ by using $\varepsilon$-$\delta$ argument
since we are hinted by the condition that $\alpha$ is continuous.
A function which is continuous at $x_0$ has a nice property near $x_0$
and this property would help us estimate $U(P, f, \alpha)$ near $x_0$.
On the contrary, if both $f$ and $\alpha$ are discontinuous at $x_0$,
it might be $f \not\in \mathscr{R}(\alpha)$.
Besides, if $f$ has too many points of discontinuity
($f(x) = 0$ if $x \in \mathbb{Q}$ and $f(x) = 1$ otherwise, for example),
then $f$ might not be Riemann-integrable on $[0, 1]$. \\\\



\textbf{Claim 1.}
\emph{$L(P, f, \alpha) = 0$.} \\

\emph{Proof of Claim 1.}
$m_i = 0$ since $\inf f(x) = 0$ on any subinterval of $[a, b]$.
So $L(P, f, \alpha) = \sum m_i \Delta \alpha_i = 0$.
Here we don't need the condition that $\alpha$ is continuous at $x_0$.
$\Box$ \\\\



\textbf{Claim 2.}
\emph{For any $\varepsilon > 0$,
there exists a partition $P$ such that $U(P, f, \alpha) < \varepsilon$.} \\

\emph{Proof of Claim 2.}
Say $x_0 \in [p_{i_0 - 1}, p_{i_0}]$ for some $i_0$.
Then
\begin{equation*}
  M_i = \sup_{p_{i - 1} \leq x \leq p_i} f(x) =
    \begin{cases}
      0 & \text{ if $i \neq i_0$}, \\
      1 & \text{ if $i = i_0$}.
    \end{cases}
\end{equation*}
So
$$U(P, f, \alpha) = \sum M_i \Delta \alpha_i = \Delta \alpha_{i_0}.$$
It is not true for any arbitrary $\alpha$. (For example, $\alpha$ has a jump on $x = x_0$.)
In fact, Exercise 6.3 shows this.
Luckily, $\alpha$ is continuous at $x_0$. So for $\varepsilon > 0$,
there exists $\delta > 0$ such that $|\alpha(x) - \alpha(x_0)| < \frac{\varepsilon}{2}$
whenever $|x - x_0| < \delta$ (and $x \in [a, b]$).
Now we pick a nice partition
$$P = \{ a, x_0 - \delta_1, x_0 + \delta_2, b \},$$
where $\delta_1 = \min\{\delta, x_0 - a\} \geq 0$
and $\delta_2 = \min\{\delta, b - x_0\} \geq 0$.
(It is a trick about resizing ``$\delta$''
to avoid considering the edge cases $x_0 = a$ or $x_0 = b$ or $a = b$.)
Then $x_0 \in [x_0 - \delta_1, x_0 + \delta_2]$
and $\Delta \alpha$ on $[x_0 - \delta_1, x_0 + \delta_2]$ is
\begin{align*}
\alpha(x_0 + \delta_2) - \alpha(x_0 - \delta_1)
&= (\alpha(x_0 + \delta_2) - \alpha(x_0)) + (\alpha(x_0) - \alpha(x_0 - \delta_1)) \\
&< \frac{\varepsilon}{2} + \frac{\varepsilon}{2} = \varepsilon.
\end{align*}
Therefore, $U(P, f, \alpha) < \varepsilon$.
$\Box$ \\\\



\emph{Proof (Definition 6.2).}
By Claim 1 and 2 and notice that $U(P, f, \alpha) \geq 0$ for any partition $P$,
\begin{align*}
\upint_a^b f d\alpha &= \inf U(P, f, \alpha) = 0, \\
\lowint_a^b f d\alpha &= \sup L(P, f, \alpha) = 0,
\end{align*}
the inf and sup again being taken over all partitions.
Hence $f \in \mathscr{R}(\alpha)$ and that $\int f d \alpha = 0$ by Definition 6.2.
$\Box$ \\

\emph{Proof (Theorem 6.6).}
By Claim 1 and 2,
$$0 \leq U(P, f, \alpha) - L(P, f, \alpha) < \varepsilon.$$
Hence $f \in \mathscr{R}(\alpha)$ by Theorem 6.6.
Furthermore,
$$\int f d \alpha = \lowint_a^b f d\alpha = \sup L(P, f, \alpha) = 0.$$
$\Box$ \\

\emph{Proof (Theorem 6.10).}
$f \in \mathscr{R}(\alpha)$ by Theorem 6.10.
Thus, by Claim 1
$$\int f d \alpha = \lowint_a^b f d\alpha = \sup L(P, f, \alpha) = 0.$$
$\Box$ \\\\



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\textbf{Exercise 6.2.}
\emph{Suppose $f \geq 0$,
$f$ is continuous on $[a,b]$, and $\int_{a}^{b} f(x) dx = 0$.
Prove that $f(x) = 0$ for all $x \in [a,b]$.
(Compare with Exercise 6.1.)} \\

For one application, see Exercise 7.20. \\

\emph{Proof.}
(Reductio ad absurdum)
If there were $p \in [a,b]$ such that $f(p) > 0$.
Since $f$ is continuous on $[a,b]$, given $\varepsilon = \frac{1}{64}f(p) > 0$
there exists $\delta > 0$
such that
\[
  |f(x) - f(p)| \leq \frac{1}{64}f(p) \text{ whenever } |x-p| \leq \delta, x \in [a,b].
\]
Hence
\[
  f(x) \geq \frac{63}{64}f(p)
\]
whenever $x \in E = [\max\{a,p-\delta\}, \min\{b,p+\delta\}] \subseteq [a,b]$.
Note that the length of $E$ is $|E| > 0$.
So
\[
  0
  = \int_{a}^{b} f(x) dx
  \geq \int_{E} f(x) dx
  \geq \int_{E} \frac{63}{64}f(p) dx
  = \frac{63}{64}f(p)|E| > 0,
\]
which is absurd.
$\Box$ \\

\emph{Note.}
(Lebesgue integral)
\emph{Let $f$ be a nonnegative measurable function.
Then $\int f = 0$ implies $f = 0$ a.e.} \\\\



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\textbf{Exercise 6.3.}
\emph{Define three functions $\beta_1$, $\beta_2$, $\beta_3$ as follows:
$\beta_j(x) = 0$ if $x < 0$, $\beta_j(x) = 1$ if $x > 0$ for $j=1,2,3$;
and $\beta_1(0) = 0$, $\beta_2(0) = 1$, $\beta_3(0) = \frac{1}{2}$.
Let $f$ be a bounded functions on $[-1,1]$.}
\begin{enumerate}
\item[(a)]
  \emph{Prove that $f \in \mathscr{R}(\beta_1)$ if and only if $f(0+) = f(0)$ and that then
  \[
    \int f d\beta_1 = f(0).
  \]}
\item[(b)]
  \emph{State and prove a similar result for $\beta_2$.}

\item[(c)]
  \emph{Prove that $f \in \mathscr{R}(\beta_3)$ if and only if $f$ is continuous at $0$.}

\item[(d)]
  \emph{If $f$ is continuous at $0$ prove that
  \[
    \int f d\beta_1 = \int f d\beta_2 = \int f d\beta_3 = f(0).
  \]} \\
\end{enumerate}



\emph{Proof of (a).}
\begin{enumerate}
\item[(1)]
  Given any $\delta > 0$,
  we have
  \[
    |f(x) - f(0)| \leq \sup_{x\in[0,\delta]} f(x) - \inf_{x\in[0,\delta]} f(x)
  \]
  if $x \in [0,\delta]$.

\item[(2)]
  Given any $\varepsilon > 0$ and $\delta > 0$.
  \emph{Show that if $f$ is bounded and $|f(x) - f(0)| < \varepsilon$ on $[0,\delta]$ then
  \[
    \sup_{x\in[0,\delta]} f(x) - \inf_{x\in[0,\delta]} f(x) < 2\varepsilon.
  \]}

  Since $f$ is bounded, there exists $x_1,x_2 \in [0,\delta]$
  such that
  \[
    f(x_1) = \sup_{x\in[0,\delta]} f(x) \:\: \text{ and } \:\:
    f(x_2) = \inf_{x\in[0,\delta]} f(x).
  \]
  By assumption,
  \[
    f(x_1) - f(x_2) \leq |f(x_1) - f(0)| + |f(0) - f(x_2)| < 2\varepsilon.
  \]

\item[(3)]
\emph{Show that $f \in \mathscr{R}(\beta_1)$ iff $f(0+) = f(0)$.}
  \begin{align*}
    &f \in \mathscr{R}(\beta_1) \\
    \Longleftrightarrow&
      \text{$\forall \varepsilon > 0$ there is $P$ such that
      $U(P,f,\beta_1) - L(P,f,\beta_1) < \varepsilon$}
        &\text{(Theorem 6.6)} \\
    \Longleftrightarrow&
      \text{$\forall \varepsilon > 0$ there is $P$ containing $0$ such that
      $U(P,f,\beta_1) - L(P,f,\beta_1) < \varepsilon$}
        &\text{(Theorem 6.4)} \\
      &\text{where $P = \{-1 = x_0 < x_1 < \ldots < x_k = 0 < \ldots < x_n = 1\}$} \\
    \Longleftrightarrow&
      \text{$\forall \varepsilon > 0$ there is $P$ containing $0$ such that
      $M_{k+1} - m_{k+1} < \varepsilon$} \\
    \Longleftrightarrow&
      \text{$\forall \varepsilon > 0$ there is $P$ containing $0$ such that
      $\sup_{x\in[0,\delta]} f(x) - \inf_{x\in[0,\delta]} f(x) < \varepsilon$} \\
      &\text{where $[x_k,x_{k+1}] = [0,\delta]$, $\delta > 0$} \\
      &\text{(Take $P = \{-1,0,\delta,1\}$ in ``$\Longleftarrow$'' direction)} \\
    \Longleftrightarrow&
      \text{$\forall \varepsilon > 0$ there is $\delta > 0$ such that
      $|f(x) - f(0)| < \varepsilon$ whenever $x \in [0,\delta]$}
        &((1)(2)) \\
      &\text{(Replace $\varepsilon$ by $\frac{\varepsilon}{2}$ in ``$\Longleftarrow$'' direction)} \\
    \Longleftrightarrow&
      \lim_{x \to 0+} f(x) = f(0).
  \end{align*}

\item[(4)]
  \emph{Show that $\int f d\beta_1 = f(0)$ if $f \in \mathscr{R}(\beta_1)$.}
  By (3) and Theorem 6.7,
  \[
    \abs{ f(0) - \int_{a}^{b} f d\beta_1 } < \varepsilon.
  \]
  Since $\varepsilon$ is arbitrary, $\int f d\beta_1 = f(0)$.
\end{enumerate}
$\Box$ \\



\emph{Proof of (b).}
\emph{Show that $f \in \mathscr{R}(\beta_2)$ if and only if $f(0-) = f(0)$ and that then
\[
  \int f d\beta_2 = f(0).
\]}

Similar to (a).
\begin{enumerate}
\item[(1)]
  Given any $\delta > 0$,
  we have
  \[
    |f(x) - f(0)| \leq \sup_{x\in[-\delta,0]} f(x) - \inf_{x\in[-\delta,0]} f(x)
  \]
  if $x \in [-\delta,0]$.

\item[(2)]
  Given any $\varepsilon > 0$ and $\delta > 0$.
  \emph{Show that if $f$ is bounded and $|f(x) - f(0)| < \varepsilon$ on $[-\delta,0]$ then
  \[
    \sup_{x\in[-\delta,0]} f(x) - \inf_{x\in[-\delta,0]} f(x) < 2\varepsilon.
  \]}

  Since $f$ is bounded, there exists $x_1,x_2 \in [-\delta,0]$
  such that
  \[
    f(x_1) = \sup_{x\in[-\delta,0]} f(x) \:\: \text{ and } \:\:
    f(x_2) = \inf_{x\in[-\delta,0]} f(x).
  \]
  By assumption,
  \[
    f(x_1) - f(x_2) \leq |f(x_1) - f(0)| + |f(0) - f(x_2)| < 2\varepsilon.
  \]

\item[(3)]
\emph{Show that $f \in \mathscr{R}(\beta_1)$ iff $f(0-) = f(0)$.}
  \begin{align*}
    &f \in \mathscr{R}(\beta_2) \\
    \Longleftrightarrow&
      \text{$\forall \varepsilon > 0$ there is $P$ such that
      $U(P,f,\beta_2) - L(P,f,\beta_2) < \varepsilon$}
        &\text{(Theorem 6.6)} \\
    \Longleftrightarrow&
      \text{$\forall \varepsilon > 0$ there is $P$ containing $0$ such that
      $U(P,f,\beta_2) - L(P,f,\beta_2) < \varepsilon$}
        &\text{(Theorem 6.4)} \\
      &\text{where $P = \{-1 = x_0 < x_1 < \ldots < x_k = 0 < \ldots < x_n = 1\}$} \\
    \Longleftrightarrow&
      \text{$\forall \varepsilon > 0$ there is $P$ containing $0$ such that
      $M_{k} - m_{k} < \varepsilon$} \\
    \Longleftrightarrow&
      \text{$\forall \varepsilon > 0$ there is $P$ containing $0$ such that
      $\sup_{x\in[-\delta,0]} f(x) - \inf_{x\in[-\delta,0]} f(x) < \varepsilon$} \\
      &\text{where $[x_{k-1},x_{k}] = [-\delta,0]$, $\delta > 0$} \\
      &\text{(Take $P = \{-1,-\delta,0,1\}$ in ``$\Longleftarrow$'' direction)} \\
    \Longleftrightarrow&
      \text{$\forall \varepsilon > 0$ there is $\delta > 0$ such that
      $|f(x) - f(0)| < \varepsilon$ whenever $x \in [-\delta,0]$}
        &((1)(2)) \\
      &\text{(Replace $\varepsilon$ by $\frac{\varepsilon}{2}$ in ``$\Longleftarrow$'' direction)} \\
    \Longleftrightarrow&
      \lim_{x \to 0-} f(x) = f(0).
  \end{align*}

\item[(4)]
  \emph{Show that $\int f d\beta_2 = f(0)$ if $f \in \mathscr{R}(\beta_2)$.}
  By (3) and Theorem 6.7,
  \[
    \abs{ f(0) - \int_{a}^{b} f d\beta_2 } < \varepsilon.
  \]
  Since $\varepsilon$ is arbitrary, $\int f d\beta_2 = f(0)$.
\end{enumerate}
$\Box$ \\



\emph{Proof of (c).}
Note that $f$ is continuous at $0$ iff $f(0+) = f(0-) = f(0)$.
Apply the same argument in (a) and (b),
we have $f \in \mathscr{R}(\beta_3)$ if and only if $f(0+) = f(0-) = f(0)$.
$\Box$ \\



\emph{Proof of (d).}
\emph{It suffices to show that
\[
  \int_{a}^{b} f d\beta_3 = f(0).
\]}

We can apply Theorem 6.12(d)(e) to $\beta_3 = \frac{1}{2}(\beta_1+\beta_2)$.
That is,
\[
  \int_{a}^{b} f d\beta_3
  = \frac{1}{2}\left[ \int_{a}^{b} f d\beta_1 + \int_{a}^{b} f d\beta_2 \right]
  = \frac{1}{2}[f(0) + f(0)] = f(0).
\]

Or apply the same argument in (a) and (b) to get
\[
  \abs{ f(0) - \int_{a}^{b} f d\beta_3 } < \varepsilon
\]
for any $\varepsilon > 0$, or $\int_{a}^{b} f d\beta_3 = f(0)$.
$\Box$ \\\\



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\textbf{Exercise 6.4.}
\emph{If
\begin{equation*}
  f(x) =
    \begin{cases}
      0 & \text{ for all irrational $x$}, \\
      1 & \text{ for all rational $x$},
    \end{cases}
\end{equation*}
prove that $f \not\in \mathscr{R}$ on $[a,b]$ for any $a < b$.} \\

\emph{Proof.}
Given any partition
\[
  P = \{a = p_0, p_1, \ldots, p_{n-1}, p_n = b \}
\]
of $[a,b]$ where $a = p_0 \leq p_1 \leq \cdots \leq p_{n-1} \leq p_n = b$.
Since $a < b$, we might assume that $a = p_0 < p_1 < \cdots < p_{n-1} < p_n = b$
by removing duplicated points.
Since $\mathbb{Q}$ and $\mathbb{R} - \mathbb{Q}$ are dense in $\mathbb{R}$, we have
\begin{align*}
  M_i &= \sup_{p_{i-1} \leq x \leq p_i} f(x) = 1, \\
  m_i &= \inf_{p_{i-1} \leq x \leq p_i} f(x) = 0, \\
  U(P,f) &= \sum_{i=1}^{n} M_i \Delta x_i = \sum_{i=1}^{n} \Delta x_i = b - a, \\
  L(P,f) &= \sum_{i=1}^{n} m_i \Delta x_i = \sum_{i=1}^{n} 0 = 0.
\end{align*}
Since $P$ is arbitrary,
\begin{align*}
  \upint_a^b f dx &= \inf U(P,f) = b-a > 0, \\
  \lowint_a^b f dx &= \sup L(P,f) = 0.
\end{align*}
Hence $f \not\in \mathscr{R}$ on $[a,b]$ for any $a < b$.
$\Box$ \\

\emph{Note.}
\begin{enumerate}
\item[(1)]
  (Lebesgue integral)
  $f$ is Lebesgue integrable.

\item[(2)]
  $f \in \mathscr{R}$ on $[a,b]$ iff $a = b$.

\item[(3)]
  (Problem 4.1 in \emph{H. L. Royden, Real Analysis, 3rd edition}.)
  \emph{Construct a sequence $\{f_n\}$ of nonnegative,
  Riemann integrable functions such that $f_n$ increases monotonically to $f$.
  What does this imply about changing the order of integration and the limiting process?}
  (Since $\mathbb{Q}$ is countable, write
  \[
    \mathbb{Q} = \{ r_1, r_2, \ldots \}.
  \]
  Define
  \begin{equation*}
    f_n(x) =
      \begin{cases}
        0 & \text{ if $x \not\in \{ r_1, \ldots, r_n \}$ }, \\
        1 & \text{ if $x \in \{ r_1, \ldots, r_n \}$ }.
      \end{cases}
  \end{equation*}
  By construction, $f_n$ increases monotonically to $f$ pointwise.
  Note that $f_n \to f$ not uniformly.
  Also, $\int_{a}^{b} f_n(x) dx = 0$ by using the same argument in Theorem 6.10.
  Therefore,
  $\lim_{n \to \infty} \int_{a}^{b} f_n(x) dx = 0$
  but $\int_{a}^{b} \lim_{n \to \infty} f_n(x) dx = \int_{a}^{b} f(x) dx$
  does not exist.) \\\\
\end{enumerate}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\textbf{Exercise 6.5.}
\emph{Suppose $f$ is a bounded real function on $[a,b]$,
and $f^2 \in \mathscr{R}$ on $[a,b]$.
Does it follow that $f \in \mathscr{R}$?
Does the answer change if we assume that $f^3 \in \mathscr{R}$?} \\

Actually we can omit the boundedness assumption of $f$
since $f^2 \in \mathscr{R}$ or $f^3 \in \mathscr{R}$. \\

\emph{Proof.}
\begin{enumerate}
\item[(1)]
\emph{Show that $f^2 \in \mathscr{R}$ on $[a,b]$ does not imply that
$f \in \mathscr{R}$ (unless $f \geq 0$ on $[a,b]$).}
Similar to Exercise 6.4,
define
\begin{equation*}
  f(x) =
    \begin{cases}
      -1 & \text{ for all irrational $x$}, \\
      1 & \text{ for all rational $x$}.
    \end{cases}
\end{equation*}
$f^2 = 1 \in \mathscr{R}$ on $[a,b]$ but
$f \not\in \mathscr{R}$ on $[a,b]$ for any $a < b$.
(The proof for the ``unless'' part is similar to (2).)

\item[(2)]
\emph{Show that $f^3 \in \mathscr{R}$ on $[a,b]$ implies that
$f \in \mathscr{R}$.}
Let $\phi(x) = x^{\frac{1}{3}}$ on $\mathbb{R}$.
By Theorem 6.11, $f(x) = \phi(f(x)^3) \in \mathscr{R}$.
(The boundedness condition in Theorem 6.11 is unnecessary.)
\end{enumerate}
$\Box$ \\



\emph{Note}
(Lebesgue integral).
\emph{Suppose that $f^2$ is Lebesgue integrable.
Does it follow that $f$ is Lebesgue integrable?
Does the answer change if we assume that $f^3$ is Lebesgue integrable?}
Both answers are no. \\\\



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\textbf{Exercise 6.6.}
\emph{Let $P$ be the Cantor set constructed in Sec. 2.44.
Let $f$ be a bounded real function on $[0,1]$ which is continuous at every point outside $P$.
Prove that $f \in \mathscr{R}$ on $[0,1]$.
(Hint: $P$ can be covered by finitely many segments
whose total length can be made as small as desired. Proceed as in Theorem 6.10.)} \\



\emph{Proof (Theorem 6.10).}
Given any $\varepsilon > 0$.
\begin{enumerate}
\item[(1)]
Note that in Section 2.44, we have
\[
  P = \bigcap_{n=1}^{\infty} E_n
\]
and each $E_n$ is the union of $2^n$ intervals, each of length $\frac{1}{3^n}$.
For each interval $[u_j,v_j] \subseteq E_n$ of $E_n$ ($1 \leq j \leq 2^n$),
we construct a slightly larger open set
\[
  (u_j-\lambda,v_j+\lambda) \supsetneq [u,v]
\]
where $\lambda = \frac{1}{2}\left( \frac{1}{2.28^n} - \frac{1}{3^n} \right) > 0$.
Each length of $(u_j-\lambda,v_j+\lambda)$ is $\frac{1}{2.28^n}$.
Write
\[
  G_n = \bigcup_{1 \leq j \leq 2^n} (u_j-\lambda,v_j+\lambda).
\]
Hence
\[
  G_n \supsetneq \bigcup_{1 \leq j \leq 2^n} [u_j,v_j] = E_n \supseteq P,
\]
and the total length $|G_n|$ of $G_n$ satisfies
\[
  |G_n|
  \leq \sum_{1 \leq j \leq 2^n} |(u_j-\lambda,v_j+\lambda)|
  = \left(\frac{2}{2.28}\right)^n.
\]
(Two different subintervals might be overlapped.)
As $n \to \infty$, $P$ can be covered by finitely many open segments
whose total length can be made as small as desired.
Now we take an integer $N$ such that
$\left(\frac{2}{2.28}\right)^N < \frac{\varepsilon}{64(M+1)}$.

\item[(2)]
Let $K = [0,1] - G_N$ be a compact set (Theorem 2.35).
By construction, $f$ is continuous on $K$ and thus $f$ is uniformly continuous.
So there is $\delta > 0$ such that $|f(s) - f(t)| < \frac{\varepsilon}{89}$
if $s, t \in K$ and $|s-t| < \delta$.

\item[(3)]
Now we construct a partition $P = \{x_0, x_1, \ldots, x_n\}$ of $[a,b]$,
as the following steps:
  \begin{enumerate}
  \item[(a)]
  Put $\frac{0}{m}, \frac{1}{m}, \ldots, \frac{m}{m}$
  in $P$ for some integer $m \geq \frac{1}{\delta}$.

  \item[(b)]
  Put $u_j-\lambda$ and $v_j+\lambda$ in $P$.

  \item[(c)]
  Remove any points in the segment $(u_j-\lambda,v_j+\lambda)$
  except $0$ and $1$.
  \end{enumerate}

\item[(4)]
  Note that $M_i - m_i \leq 2M$ $(1 \leq i \leq n)$ where $M = \sup|f(x)|$ is defined.
  Hence,
  \[
    U(P,f) - L(P,f)
    \leq \frac{\varepsilon}{89} + 2M \cdot \frac{\varepsilon}{64(M+1)}
    \leq \varepsilon.
  \]
  Since $\varepsilon$ is arbitrary, Theorem 6.6 shows that $f \in \mathscr{R}$.
\end{enumerate}
$\Box$ \\



\textbf{Supplement (Lebesgue's criterion for Riemann-integrability).}
\emph{(Theorem 11.33.) Let $f$ be a bounded real function on $[a,b]$
and let $D$ be the set of discontinuities of $f$ in $[a,b]$.
Then $f \in \mathscr{R}$ on $[a,b]$ if and only if $D$ has measure zero.} \\\\



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\textbf{Exercise 6.7.}
\emph{Suppose $f$ is a real function on $(0,1]$ and $f \in \mathscr{R}$ on $[c,1]$
for every $c > 0$.
Define
\[
  \int_{0}^{1}f(x)dx = \lim_{c \to 0} \int_{c}^{1}f(x)dx
\]
if this limit exists (and is finite).}
\begin{enumerate}
  \item[(a)]
  \emph{If $f \in \mathscr{R}$ on $[0,1]$,
  show that this definition of the integral agrees with the old one.}

  \item[(b)]
  \emph{Construct a function such that the above limit exists,
  although it fails to exist with $|f|$ in place of $f$.} \\
\end{enumerate}

\emph{Proof of (a).}
\begin{enumerate}
\item[(1)]
  Since $f \in \mathscr{R}$ on $[0,1]$, $f$ is bounded or
  $|f| \leq M$ for some real $M$.

\item[(2)]
For any $0 < c < 1$,
we have
\begin{align*}
  \abs{ \int_{0}^{1} f(x)dx - \int_{c}^{1} f(x)dx }
  &= \abs{ \int_{0}^{c} f(x)dx }
    &\text{(Theorem 6.12(c))}\\
  &\leq Mc.
    &\text{(Theorem 6.12(d))}
\end{align*}

\item[(3)]
Given any $\varepsilon > 0$, there exists $\delta = \frac{\varepsilon}{M+1} > 0$
such that
\[
  \abs{ \int_{0}^{c} f(x)dx - \int_{0}^{1} f(x)dx }
  \leq Mc
  < M \delta
  = M \cdot \frac{\varepsilon}{M+1}
  < \varepsilon
\]
whenever $0 < c < \delta$.
Hence $\lim_{c \to 0} \int_{0}^{c} f(x)dx = \int_{0}^{1} f(x)dx$.
\end{enumerate}
$\Box$ \\



\emph{Proof of (b)(Construct by nonabsolutely convergent series).}
\begin{enumerate}
\item[(1)]
Given any nonabsolutely (conditionally) convergent series $\sum_{k=1}^{n} a_k$
(take $\sum \frac{(-1)^n}{n}$ for example and then see Remark 3.46),
we define $f$ on $(0,1]$ by
\[
  f(x) = 2^{n} a_n
\]
if $\frac{1}{2^{n}} < x \leq \frac{1}{2^{n-1}}$ as $n = 1,2,\ldots$.

\item[(2)]
By construction,
\[
  \int_{\frac{1}{2^{n}}}^{\frac{1}{2^{n-1}}} f(x) dx
  = \left( \frac{1}{2^{n-1}} - \frac{1}{2^{n}}\right) 2^n a_n = a_n.
\]
and thus
\[
  \int_{\frac{1}{2^{n}}}^{1} f(x) dx
  = \int_{\frac{1}{2^{n}}}^{\frac{1}{2^{n-1}}} f(x) dx
    + \cdots
    + \int_{\frac{1}{2}}^{1} f(x) dx
  = \sum_{k=1}^{n} a_k.
\]

\item[(3)]
Given any $\varepsilon > 0$.
Since $\sum a_n$ is convergent, there exists a common integer $N$
such that
\[
  |a_n| \leq \frac{\varepsilon}{89}
\]
and
\[
  \abs{ \sum_{k=1}^{n} a_k - A } \leq \frac{\varepsilon}{64}
\]
for some real $A$ whenever $n \geq N$
(Definition 3.21 and Theorem 3.23).
Therefore, for any $0 < c \leq \frac{1}{2^N}$,
say $\frac{1}{2^{n+1}} < c \leq \frac{1}{2^n} \leq \frac{1}{2^N}$ for some $n \geq N$,
we have
\begin{align*}
  \abs{ \int_{c}^{1} f(x) dx - A }
  &= \abs{ \int_{c}^{\frac{1}{2^{n}}} f(x) dx
    + \int_{\frac{1}{2^{n}}}^{1} f(x) dx
    - A } \\
  &\leq \abs{ \left( \frac{1}{2^{n}} - c \right) 2^{n+1} a_{n+1} }
    + \abs{ \sum_{k=1}^{n} a_k - A } \\
  &\leq \abs{ a_{n+1} } + \abs{ \sum_{k=1}^{n} a_k - A } \\
  &\leq \frac{\varepsilon}{89} + \frac{\varepsilon}{64} \\
  &\leq \varepsilon.
\end{align*}
Hence, $\lim_{c \to 0} \int_{c}^{1} f(x) dx = A$ exists.

\item[(4)]
Since
\[
  \int_{\frac{1}{2^{n}}}^{1} |f(x)| dx
  = \int_{\frac{1}{2^{n}}}^{\frac{1}{2^{n-1}}} |f(x)| dx
    + \cdots
    + \int_{\frac{1}{2}}^{1} |f(x)| dx
  = \sum_{k=1}^{n} |a_k| \to \infty
\]
as $n \to \infty$,
$\lim_{c \to 0} \int_{c}^{1}f(x)dx$ does not exist.
(Or show that $\lim_{c \to 0} \int_{c}^{1}f(x)dx = \infty$ by definition directly.)
\end{enumerate}
$\Box$ \\\\



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\textbf{Exercise 6.8.}
\emph{Suppose $f \in \mathscr{R}$ on $[a,b]$ for every $b > a$ where $a$ is fixed.
Define
\[
  \int_{a}^{\infty} f(x) dx
  = \lim_{b \to \infty} \int^b_a f(x) dx
\]
if this limit exists (and is finite).
In that case, we say that the integral on the left \textbf{converges}.
If it also converges after $f$ has been replaced by $|f|$,
it is said to converge \textbf{absolutely}.
Assume that $f(x) \geq 0$ and that $f$ decreases monotonically on $[1,\infty)$.
Prove that
\[
  \int_1^{\infty} f(x) dx
\]
converges if and only if
\[
  \sum_{n=1}^{\infty} f(n)
\]
converges.
(This is the so-called ``integral test'' for convergence of series.)} \\



\emph{Proof.}
Similar to Exercise 8.9.
\begin{enumerate}
\item[(1)]
Define
\begin{align*}
  a_n &= \int_{1}^{n} f(x) dx, \\
  b_n &= \sum_{k=1}^{n} f(k), \\
  c_n &= b_n - a_n
\end{align*}
for $n = 1,2,3,\ldots$.

\item[(2)]
\emph{Show that $\{c_n\}$ decreases.}
Since $f$ decreases monotonically on $[1,\infty)$, we have
\begin{align*}
  c_n - c_{n+1}
  &= (b_{n} - a_{n}) - (b_{n+1} - a_{n+1}) \\
  &= (a_{n+1} - a_{n}) - (b_{n+1} - b_{n}) \\
  &= \int_{n}^{n+1} f(x) dx - f(n+1) \\
  &\geq \int_{n}^{n+1} f(n+1) dx - f(n+1) \\
  &= f(n+1) - f(n+1) \\
  &= 0.
\end{align*}

\item[(3)]
\emph{Show that $\{c_n\}$ is bounded.}
Since $f$ decreases monotonically on $[1,\infty)$,
\begin{align*}
  c_{n}
  &= b_n - a_n \\
  &= \sum_{k=1}^{n} f(k) - \int_{1}^{n} f(x) dx \\
  &= \sum_{k=1}^{n} f(k) - \sum_{k=1}^{n-1} \int_{k}^{k+1} f(x) dx \\
  &\geq \sum_{k=1}^{n} f(k) - \sum_{k=1}^{n-1} \int_{k}^{k+1} f(k) dx \\
  &= \sum_{k=1}^{n} f(k) - \sum_{k=1}^{n-1} f(k) \\
  &= f(n).
\end{align*}
Since $f(n)$ is nonnegative, $c_n \geq 0$.

\item[(4)]
By (2)(3), $\{c_n\}$ converges (Theorem 3.14).

\item[(5)]
Since $c_n = b_n - a_n$ and $\{c_n\}$ converges,
$\{a_n\}$ converges if and only if $\{b_n\}$ converges,
or $\int_1^{\infty} f(x) dx$ converges if and only if
$\sum_{n=1}^{\infty} f(n)$ converges.
\end{enumerate}
$\Box$ \\\\



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\textbf{Exercise 6.9.}
\emph{Show that integration by parts can sometimes be applied to the
``improper'' integrals defined in Exercise 6.7 and 6.8.
(State appropriate hypotheses, formulate a theorem, and prove it.)
For instance show that
\[
  \int_{0}^{\infty} \frac{\cos x}{1+x} dx
  = \int_{0}^{\infty} \frac{\sin x}{(1+x)^2} dx.
\]
Show that one of these integrals converges \textbf{absolutely}, but that
the other does not.} \\



\emph{Proof.}
\begin{enumerate}
\item[(1)]
\emph{Suppose $F$ and $G$ are differentiable functions on $(0,1]$,
$F' = f \in \mathscr{R}$ on $[c,1]$ and $G' = g \in \mathscr{R}$ on $[c,1]$
for every $c > 0$.
Then
\[
  \int_{0}^{1} F(x)g(x) dx
  = F(1)G(1) - \lim_{c \to 0} F(c)G(c)
  - \int_{0}^{1} f(x)G(x) dx
\]
if any two of $\int_{0}^{1} F(x)g(x) dx$, $\int_{0}^{1} f(x)G(x) dx$
or $\lim_{c \to 0} F(c)G(c)$ exist.}
Theorem 6.22 (integration by parts) implies that
\[
  \int_{c}^{1} F(x)g(x) dx
  = F(1)G(1) - F(c)G(c)
  - \int_{c}^{1} f(x)G(x) dx.
\]
Since any two of $\int_{0}^{1} F(x)g(x) dx$ or $\int_{0}^{1} f(x)G(x) dx$
or $\lim_{c \to 0} F(c)G(c)$ exist,
the rest one exists and satisfies the identity
\[
  \int_{0}^{1} F(x)g(x) dx
  = F(1)G(1) - \lim_{c \to 0} F(c)G(c)
  - \int_{0}^{1} f(x)G(x) dx
\]
by letting $c \to 0$.

\item[(2)]
\emph{Suppose $F$ and $G$ are differentiable functions on $[a,b]$
for every $b > a$ where $a$ is fixed,
$F' = f \in \mathscr{R}$ on $[a,b]$ and $G' = g \in \mathscr{R}$ on $[a,b]$.
Then
\[
  \int_{a}^{\infty} F(x)g(x) dx
  = \lim_{b \to \infty}F(b)G(b) - F(a)G(a)
  - \int_{a}^{\infty} f(x)G(x) dx
\]
if any two of $\int_{a}^{\infty} F(x)g(x) dx$, $\int_{a}^{\infty} f(x)G(x) dx$
or $\lim_{b \to \infty}F(b)G(b)$ exist.}
Theorem 6.22 (integration by parts) implies that
\[
  \int_{a}^{b} F(x)g(x) dx
  = F(b)G(b) - F(a)G(a)
  - \int_{a}^{b} f(x)G(x) dx.
\]
Since any two of $\int_{a}^{\infty} F(x)g(x) dx$ or $\int_{a}^{\infty} f(x)G(x) dx$
or $\lim_{b \to \infty}F(b)G(b)$ exist,
the rest one exists and satisfies the identity
\[
  \int_{a}^{\infty} F(x)g(x) dx
  = \lim_{b \to \infty}F(b)G(b) - F(a)G(a)
  - \int_{a}^{\infty} f(x)G(x) dx
\]
by letting $b \to \infty$.

\item[(3)]
\emph{Show that}
\[
  \int_{0}^{\infty} \frac{\cos x}{1+x} dx
  = \int_{0}^{\infty} \frac{\sin x}{(1+x)^2} dx.
\]
Put $a = 0$, $F(x) = \frac{1}{1+x}$ and $G(x) = \sin x$ in
\[
  \int_{a}^{\infty} F(x)g(x) dx
  = \lim_{b \to \infty}F(b)G(b) - F(a)G(a)
  - \int_{a}^{\infty} f(x)G(x) dx
\]
to get
\[
  \int_{0}^{\infty} \frac{(\sin x)'}{1+x} dx
  = \lim_{b \to \infty}\frac{\sin(b)}{1+b} - \frac{\sin(0)}{1+0}
  - \int_{0}^{\infty} \left(\frac{1}{1+x}\right)' \sin x dx
\]
or
\[
  \int_{0}^{\infty} \frac{\cos x}{1+x} dx
  = \int_{0}^{\infty} \frac{\sin x}{(1+x)^2} dx.
\]

\item[(4)]
\emph{Show that
\[
  \int_{0}^{\infty} \frac{\sin x}{(1+x)^2} dx
\]
converges absolutely.}
Notice that
\begin{align*}
  \int_{0}^{\infty} \abs{\frac{\sin x}{(1+x)^2}} dx
  &\leq \int_{0}^{\infty} \frac{1}{(1+x)^2} dx \\
  &= \lim_{b \to \infty} \left[ -\frac{1}{1+x} \right]_{0}^{b} - (-1) \\
  &= 1.
\end{align*}

\item[(5)]
\emph{Show that
\[
  \int_{0}^{\infty} \frac{\cos x}{1+x} dx
\]
converges conditionally.}
By (3)(4), $\int_{0}^{\infty} \frac{\cos x}{1+x} dx$ converges.
Note that
\[
  \cos x \geq \frac{1}{2}
\]
if $x \in [-\frac{\pi}{3} + 2n\pi, \frac{\pi}{3} + 2n\pi]$ for $n = 1,2,3,\ldots$.
Hence
\begin{align*}
  \int_{0}^{\infty} \abs{\frac{\cos x}{1+x}} dx
  &\geq
  \sum_{n=1}^{\infty} \int_{-\frac{\pi}{3} + 2n\pi}^{\frac{\pi}{3} + 2n\pi}
    \abs{\frac{\cos x}{1+x}} dx \\
  &\geq
  \sum_{n=1}^{\infty} \int_{-\frac{\pi}{3} + 2n\pi}^{\frac{\pi}{3} + 2n\pi}
    \frac{\frac{1}{2}}{1+\frac{\pi}{3} + 2n\pi} dx \\
  &=
  \sum_{n=1}^{\infty} \frac{2\pi}{3} \cdot \frac{\frac{1}{2}}{1+\frac{\pi}{3} + 2n\pi} \\
  &>
  \frac{\pi}{3}
    \sum_{n=1}^{\infty} \frac{1}{\pi + \pi + 2n\pi} \\
  &=
  \frac{1}{6} \sum_{n=1}^{\infty} \frac{1}{n+1}.
\end{align*}
By Theorem 3.28, $\sum_{n=1}^{\infty} \frac{1}{n+1} = \infty$
and thus $\int_{0}^{\infty} \frac{\cos x}{1+x} dx$ does not converge absolutely.
\end{enumerate}
$\Box$ \\\\



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\textbf{Exercise 6.10.}
\emph{Let $p$ and $q$ be positive real integers such that
\[
  \frac{1}{p} + \frac{1}{q} = 1.
\]
Prove the following statements.}
\begin{enumerate}
  \item[(a)]
  \emph{If $u \geq 0$ and $v \geq 0$, then
  \[
    uv \leq \frac{u^p}{p} + \frac{v^q}{q}.
  \]
  Equality holds if and only if $u^p = v^q$.}

  \item[(b)]
  \emph{If $f \in \mathscr{R}(\alpha)$, $g \in \mathscr{R}(\alpha)$,
  $f \geq 0$, $g \geq 0$, and
  \[
    \int_{a}^{b} f^p d\alpha = \int_{a}^{b} g^q d\alpha = 1,
  \]
  then
  \[
    \int_{a}^{b} fg d\alpha \leq 1.
  \]}

  \item[(c)]
  \emph{If $f$ and $g$ are complex functions in $\mathscr{R}(\alpha)$, then
  \[
    \abs{ \int_{a}^{b} fg d\alpha }
    \leq
    \left\{ \int_{a}^{b} |f|^p d\alpha \right\}^{\frac{1}{p}}
    \left\{ \int_{a}^{b} |g|^q d\alpha \right\}^{\frac{1}{q}}.
  \]
  This is \textbf{H\"older's inequality}.
  When $p=q=2$ it is usually called the Schwarz inequality.
  (Note that Theorem 1.35 is a very special case of this.)}

  \item[(d)]
  \emph{Show that H\"older's inequality is also true for the ``improper'' integrals
  described in Exercise 6.7 and 6.8.} \\
\end{enumerate}



\emph{Proof of (a)(Young's inequality).}
\begin{enumerate}
  \item[(1)]
  $u = 0$ or $v = 0$ is nothing to do.
  For $u > 0$ and $v > 0$, we give some different proofs.

  \item[(2)]
  First proof.
  \begin{align*}
    uv
    &= \exp(\log(uv)) \\
    &= \exp(\frac{1}{p}\log(u^p) + \frac{1}{q}\log(v^q)) \\
    &\leq \frac{1}{p} \exp(\log(u^p)) + \frac{1}{q}\exp(\log(v^q))
      &\text{(Convexity of $\exp(x)$)} \\
    &= \frac{u^p}{p} + \frac{v^q}{q}.
  \end{align*}
  Here the convexity of $\exp(x)$ can be derived
  by the fact that $(\exp(x))'' > 0$ and Exercise 5.14.
  The fact that the equality holds if and only if $u^p = v^q$
  is derived from the strictly convexity of $\exp(x)$ additionally.
  (For the details about the exponential and logarithmic functions,
  might see Chapter 8.)

  \item[(3)]
  Second proof.
  \begin{align*}
    \log(\frac{u^p}{p} + \frac{v^q}{q})
    &\geq \frac{1}{p} \log(u^p) + \frac{1}{q}\log(v^q)
      &\text{(Concavity of $\log(x)$)} \\
    &= \log(u) + \log(v) \\
    &= \log(uv).
  \end{align*}
  Since $\log(x)$ increases monotonically ($(\log(x))' = \frac{1}{x} > 0$ if $x > 0$),
  $\frac{u^p}{p} + \frac{v^q}{q} \geq uv$
  (or take the exponential function to get the same conclusion).
  Here the concavity of $\log(x)$ can be derived
  by the fact that $(\log(x))'' < 0$ and a statement that
  $f''(x) \leq 0$ if and only if $f$ is concave.
  The fact that the equality holds if and only if $u^p = v^q$
  is derived from the strictly concavity of $\log(x)$ additionally.
  (The proof is analogous to Exercise 5.14.)

  \item[(4)]
  Third proof.
  \emph{Suppose that $f:[0,\infty) \to [0,\infty)$ is a strictly increasing continuous function
  such that $f(0) = 0$ and $\lim_{x \to \infty} f(x) = \infty$.
  Then
  \[
    uv \leq \int_{0}^{u} f(x)dx + \int_{0}^{v} f^{-1}(x)dx
  \]
  for every $u,v \geq 0$, and equality occurs if and only if $v = f(u)$.}
  Define
  \[
    F(x) = -xf(x) + \int_{0}^{x} f(t)dt + \int_{0}^{f(x)} f^{-1}(t)dt.
  \]
  By Theorem 6.20 (the fundamental theorem of calculus) and Theorem 5.5 (chain rule),
  \[
    F'(x) = -(f(x) + xf'(x))+ f(x) + f'(x) f^{-1}(f(x)) = 0.
  \]
  Hence $F(x)$ is a constant on $(0,u)$ (Theorem 5.11(b)).
  Note that $F(x)$ is continuous on $[0,u]$ and $F(0) = 0$,
  so $F(x) = 0$ on $[0,u]$
  or
  \[
    \int_{0}^{x} f(t)dt + \int_{0}^{f(x)} f^{-1}(t)dt = xf(x).
  \]
  Take $x = u$ to get
  \[
    \int_{0}^{u} f(x)dx + \int_{0}^{f(u)} f^{-1}(x)dx = uf(u).
  \]
  Hence
  \begin{align*}
    &\int_{0}^{u} f(x)dx + \int_{0}^{v} f^{-1}(x)dx - uv \\
    =&
    \int_{0}^{u} f(x)dx + \int_{0}^{f(u)} f^{-1}(x)dx + \int_{f(u)}^{v} f^{-1}(x)dx - uv \\
    =&
    uf(u) + \int_{f(u)}^{v} f^{-1}(x)dx - uv \\
    =&
    \int_{f(u)}^{v} [ f^{-1}(x)-f^{-1}(f(u)) ] dx \\
    \geq&
    0.
  \end{align*}
  The last inequality holds since $f$ is strictly increasing
  and thus $f^{-1}$ is strictly increasing too.
  Besides, the equality holds if and only if $f(u) = v$.
  Now the conclusion holds by taking $f(x) = x^{p-1}$ in
  \[
    uv \leq \int_{0}^{u} f(x)dx + \int_{0}^{v} f^{-1}(x)dx
  \]
  and the equality holds if and only if $u^p = v^q$.
\end{enumerate}
$\Box$ \\



\emph{Proof of (b).}
Every integral is well-defined (Theorem 6.11 and Theorem 6.13(a)).
Let $u = f \geq 0$ and $v = g \geq 0$ in (a).
Integrate both sides of the inequality
\[
  fg \leq \frac{f^p}{p} + \frac{g^q}{q}
\]
to get
\begin{align*}
  \int_{a}^{b} fg d\alpha
  &\leq \int_{a}^{b} \left( \frac{f^p}{p} + \frac{g^q}{q} \right) d\alpha
    &\text{(Theorem 6.12(b))} \\
  &= \int_{a}^{b} \frac{f^p}{p} d\alpha + \int_{a}^{b} \frac{g^q}{q} d\alpha
    &\text{(Theorem 6.12(a))} \\
  &= \frac{1}{p} \int_{a}^{b} f^p d\alpha + \frac{1}{q} \int_{a}^{b} g^q d\alpha
    &\text{(Theorem 6.12(a))} \\
  &= \frac{1}{p} + \frac{1}{q}
    &\text{(Assumption)} \\
  &= 1.
\end{align*}
The equality holds if $f^p = g^q$.
Note that the equality does not hold only if $f^p = g^q$.
(Consider $\alpha$ is constant on some subinterval $[c,d] \subsetneq [a,b]$.)
Luckily, it is true for the additional assumption that
$\alpha(x) = x$ and $f, g$ are continuous on $[a,b]$.
$\Box$ \\



\emph{Proof of (c).}
There are three possible cases.
\begin{enumerate}
\item[(1)]
  The case $\left\{ \int_{a}^{b} |f|^p d\alpha \right\}^{\frac{1}{p}} = 0$.
  So $\int_{a}^{b} |f|^p d\alpha = 0$.

  \begin{enumerate}
  \item[(a)]
  \emph{Show that $\int_{a}^{b} |f| d\alpha = 0$ if $\int_{a}^{b} |f|^p d\alpha = 0$.}
  (Reductio ad absurdum)
  If $\int_{a}^{b} |f| d\alpha = A > 0$, then given $\varepsilon = \frac{A}{2} > 0$,
  there exists a partition $P_0 = \{a=x_0 \leq \cdots \leq x_n = b \}$ such that
  \[
    \sum_{i=0}^{n} m_i \Delta \alpha_i > \frac{A}{2},
  \]
  where $m_i = \inf_{x \in [x_{i-1},x_i]} |f|$ and
  $\Delta \alpha_i = \alpha(x_i) - \alpha(x_{i-1})$.
  By the pigeonhole principle,
  there exists $1 \leq i_0 \leq n$
  such that
  \[
    L(P_0,|f|,\alpha) = m_{i_0} \Delta \alpha_{i_0} > \frac{A}{2n} > 0.
  \]
  Especially, $m_{i_0} > 0$ and $\Delta \alpha_{i_0} > 0$.
  Now we consider $L(P,|f|^p,\alpha)$.
  Hence
  \[
    L(P_0,|f|^p,\alpha)
  = \sum_{i=0}^{n} m_i^p \Delta \alpha_i
  \geq m_{i_0}^p \Delta \alpha_{i_0} > 0,
  \]
  or
  \[
    \lowint_{a}^{b}|f|d\alpha = \sup L(P,f,\alpha) \geq m_{i_0}^p \Delta \alpha_{i_0} > 0,
  \]
  which is absurd.

  \item[(b)]
  \emph{Show that $\int_{a}^{b} |fg| d\alpha = 0$ if $\int_{a}^{b} |f| d\alpha = 0$.}
  Since $g \in \mathscr{R}(\alpha)$, $|g|$ is bounded by some real $M$ on $[a,b]$,
  that is, $|g(x)| \leq M$.
  Hence
  \[
    0
  \leq \int_{a}^{b} |fg| d\alpha
  \leq \int_{a}^{b} M|f| d\alpha
  = M \int_{a}^{b}|f| d\alpha
  = 0.
  \]
  Therefore $\int_{a}^{b} |fg| d\alpha = 0$.
  \end{enumerate}
  By (a)(b), $\int_{a}^{b} |fg| d\alpha = 0$
  and thus H\"older's inequality holds for this case.

\item[(2)]
  The case $\left\{ \int_{a}^{b} |g|^q d\alpha \right\}^{\frac{1}{q}} = 0$.
  Similar to (1).

\item[(3)]
  If both
  $\left\{ \int_{a}^{b} |f|^p d\alpha \right\}^{\frac{1}{p}} > 0$
  and
  $\left\{ \int_{a}^{b} |g|^q d\alpha \right\}^{\frac{1}{q}} > 0$,
  then we apply (b)
  to
  \[
    F(x) = \frac{|f(x)|}{\left\{ \int_{a}^{b} |f(x)|^p d\alpha \right\}^{\frac{1}{p}}}
    \qquad
    \text{ and }
    \qquad
    G(x) = \frac{|g(x)|}{\left\{ \int_{a}^{b} |g(x)|^q d\alpha \right\}^{\frac{1}{q}}}.
  \]
  Here $F(x) \geq 0$ and $G(x) \geq 0$ are well-defined and Riemann integrable.
  Thus the conclusion holds.
  The equality holds if $F(x)^p = G(x)^q$
  or
  \[
    \frac{|f|^p}{\int_{a}^{b} |f|^p d\alpha}
    =
    \frac{|g|^q}{\int_{a}^{b} |g|^q d\alpha}.
  \]
  Note that the equality does not hold only if
  $\frac{|f|^p}{\int_{a}^{b} |f|^p d\alpha}
  =
  \frac{|g|^q}{\int_{a}^{b} |g|^q d\alpha}$.
  Luckily, it is true for the additional assumption that
  $\alpha(x) = x$ and $f, g$ are continuous on $[a,b]$.
\end{enumerate}
By (1)(2)(3),
in any case the equality holds if
\[
  |f|^p \int_{a}^{b} |g|^q d\alpha = |g|^q \int_{a}^{b} |f|^p d\alpha.
\]
In addition, if $\alpha(x) = x$ and $f, g$ are continuous on $[a,b]$,
then the equality holds if and only if
\[
  |f|^p \int_{a}^{b} |g|^q d\alpha = |g|^q \int_{a}^{b} |f|^p d\alpha.
\]
$\Box$ \\



\emph{Proof of (d).}
\begin{enumerate}
\item[(1)]
  \emph{Suppose $f$ and $g$ are real functions on $(0,1]$
  and $f, g \in \mathscr{R}$ on $[c,1]$ for every $c > 0$.
  Show that
  \[
    \abs{ \int_{0}^{1} fg dx }
    \leq
    \left\{ \int_{0}^{1} |f|^p dx \right\}^{\frac{1}{p}}
    \left\{ \int_{0}^{1} |g|^q dx \right\}^{\frac{1}{q}}.
  \]
  Here $\int_{0}^{1}$ is one improper integral defined in Exercise 6.7.}
  \begin{enumerate}
  \item[(a)]
    By (c), we have
    \[
      \abs{ \int_{c}^{1} fg dx }
      \leq
      \left\{ \int_{c}^{1} |f|^p dx \right\}^{\frac{1}{p}}
      \left\{ \int_{c}^{1} |g|^q dx \right\}^{\frac{1}{q}}
    \]
    for any $c \in (0,1]$.
    Here every integral is well-defined (Theorem 6.11 and Theorem 6.13).

  \item[(b)]
    Since every integral is $\geq 0$, by taking the limit in the right hand side
    we have
    \begin{align*}
      \abs{ \int_{c}^{1} fg dx }
      &\leq
      \left\{ \int_{c}^{1} |f|^p dx \right\}^{\frac{1}{p}}
      \left\{ \int_{c}^{1} |g|^q dx \right\}^{\frac{1}{q}} \\
      &\leq
      \left\{ \int_{0}^{1} |f|^p dx \right\}^{\frac{1}{p}}
      \left\{ \int_{0}^{1} |g|^q dx \right\}^{\frac{1}{q}}.
    \end{align*}
    It is possible that $\left\{ \int_{0}^{1} |f|^p dx \right\}^{\frac{1}{p}} = \infty$
    or $\left\{ \int_{0}^{1} |g|^q dx \right\}^{\frac{1}{q}} = \infty$.

  \item[(c)]
    Now $\abs{ \int_{c}^{1} fg dx }$ is bounded by
    $\left\{ \int_{0}^{1} |f|^p dx \right\}^{\frac{1}{p}}
    \left\{ \int_{0}^{1} |g|^q dx \right\}^{\frac{1}{q}}$.
    Take limit to get
    \[
      \abs{ \int_{0}^{1} fg dx }
      \leq
      \left\{ \int_{0}^{1} |f|^p dx \right\}^{\frac{1}{p}}
      \left\{ \int_{0}^{1} |g|^q dx \right\}^{\frac{1}{q}}
    \]
    even if some limit is divergent.
  \end{enumerate}

  \item[(2)]
  \emph{Suppose $f$ and $g$ are real functions on $[a,b]$
  and $f, g \in \mathscr{R}$ on $[a,b]$ for every $b > a$ where $a$ is fixed.
  Show that
  \[
    \abs{ \int_{a}^{\infty} fg dx }
    \leq
    \left\{ \int_{a}^{\infty} |f|^p dx \right\}^{\frac{1}{p}}
    \left\{ \int_{a}^{\infty} |g|^q dx \right\}^{\frac{1}{q}}.
  \]
  Here $\int_{a}^{\infty}$ is one improper integral defined in Exercise 6.8.}
  Same as (1).
\end{enumerate}
$\Box$ \\\\



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\textbf{Exercise 6.11.}
\emph{Let $\alpha$ be a fixed increasing function on $[a,b]$.
For $u \in \mathscr{R}(\alpha)$, define
\[
  \norm{u}_2 = \left\{ \int_{a}^{b} |u|^2 d\alpha \right\}^{\frac{1}{2}}.
\]
Suppose $f,g,h \in \mathscr{R}(\alpha)$, and prove the triangle inequality
\[
  \norm{f-h}_2 \leq \norm{f-g}_2 + \norm{g-h}_2
\]
as a consequence of the Schwarz inequality, as in the proof of Theorem 1.37.} \\

\emph{Proof.}
\begin{enumerate}
\item[(1)]
By Exercise 6.10(c) with $p=q=2$, we have
\begin{align*}
  \int_{a}^{b} |f-g||g-h| d\alpha
  &=
    \abs{ \int_{a}^{b} |f-g||g-h| d\alpha } \\
  &\leq
    \left\{ \int_{a}^{b} |f-g|^2 dx \right\}^{\frac{1}{2}}
    \left\{ \int_{a}^{b} |g-h|^2 dx \right\}^{\frac{1}{2}} \\
  &= \norm{f-g}_2 \norm{g-h}_2.
\end{align*}
Every integral is well-defined (Theorem 6.12 and Theorem 6.13 (or Theorem 6.11)).

\item[(2)]
Since
\begin{align*}
  \norm{f-h}_2^2
  &= \int_{a}^{b} |f-h|^2 d\alpha \\
  &\leq \int_{a}^{b} (|f-g|+|g-h|)^2 d\alpha
    &\text{(Triangle inequality)} \\
  &= \int_{a}^{b} (|f-g|^2 + 2|f-g||g-h| + |g-h|^2) d\alpha \\
  &= \int_{a}^{b} |f-g|^2 d\alpha
    + 2\int_{a}^{b} |f-g||g-h| d\alpha
    + \int_{a}^{b} |g-h|^2 d\alpha \\
  &\leq
    \norm{f-g}_2^2 + 2 \norm{f-g}_2 \norm{g-h}_2 + \norm{g-h}_2^2
    &\text{((1))} \\
  &= (\norm{f-g}_2 + \norm{g-h}_2)^2,
\end{align*}
we have
\[
  \norm{f-h}_2 \leq \norm{f-g}_2 + \norm{g-h}_2.
\]
Here every integral is well-defined (Theorem 6.12 and Theorem 6.13 (or Theorem 6.11)).

\end{enumerate}
$\Box$ \\\\



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\textbf{Exercise 6.12.}
\emph{With the notations of Exercise 6.11,
suppose $f \in \mathscr{R}(\alpha)$ and $\varepsilon > 0$.
Prove that there exists a continuous function $g$ on $[a,b]$
such that $\norm{f-g}_2 < \varepsilon$.
(Hint: Let $P = \{a=x_0 \leq \cdots \leq x_n = b\}$ be a suitable partition of $[a,b]$,
define
\[
  g(t) = \frac{x_i-t}{\Delta x_i} f(x_{i-1}) + \frac{t-x_{i-1}}{\Delta x_i} f(x_i)
\]
if $x_{i-1} \leq t \leq x_i$.)} \\

\emph{Proof.}
Given $\varepsilon > 0$.
\begin{enumerate}
\item[(1)]
There are some real numbers $m$ and $M$
such that $m \leq f(x) \leq M$ if $x \in [a,b]$ since $f \in \mathscr{R}(\alpha)$
or $f$ is bounded on $[a,b]$.
By Theorem 6.6, there exists a partition
$P = \{a=x_0 \leq \cdots \leq x_n = b\}$ such that
\[
  U(P,f,\alpha) - L(P,f,\alpha) < \frac{\varepsilon^2}{M - m + 1}.
\]
Here
\begin{align*}
  U(P,f,\alpha) &= \sum_{i=1}^n M_i \Delta \alpha_i
    \text{ where } M_i = \sup_{x_{i-1} \leq x \leq x_i} f(x) \\
  L(P,f,\alpha) &= \sum_{i=1}^n m_i \Delta \alpha_i
    \text{ where } m_i = \inf_{x_{i-1} \leq x \leq x_i} f(x).
\end{align*}

\item[(2)]
For such partition $P$, define $g$ on $[a,b]$ by
\[
  g(t) = \frac{x_i-t}{\Delta x_i} f(x_{i-1}) + \frac{t-x_{i-1}}{\Delta x_i} f(x_i)
\]
if $x_{i-1} \leq t \leq x_i$.
So that
\begin{align*}
  \abs{ f(t) - g(t) }
  &= \abs{ \left( \frac{x_i-t}{\Delta x_i} + \frac{t-x_{i-1}}{\Delta x_i} \right) f(t)
    - \frac{x_i-t}{\Delta x_i} f(x_{i-1}) + \frac{t-x_{i-1}}{\Delta x_i} f(x_i) } \\
  &= \abs{ \frac{x_i-t}{\Delta x_i}(f(t) - f(x_{i-1}))
    +  \frac{t-x_{i-1}}{\Delta x_i}(f(t) - f(x_i)) } \\
  &\leq \frac{x_i-t}{\Delta x_i}\abs{ f(t) - f(x_{i-1}) }
    +  \frac{t-x_{i-1}}{\Delta x_i}\abs{ f(t) - f(x_i) } \\
  &\leq \frac{x_i-t}{\Delta x_i} (M_i - m_i) + \frac{t-x_{i-1}}{\Delta x_i}(M_i - m_i) \\
  &= M_i - m_i
\end{align*}
if $x_{i-1} \leq t \leq x_i$.
Especially,
\[
  \abs{ f(t) - g(t) } \leq M - m
\]
if $a \leq t \leq b$.

\item[(3)]
Note that the integral $\int_{a}^{b} |f-g|^2 d\alpha$ is well-defined
(Theorem 6.8, Theorem 6.11 and Theorem 6.12).
So that
\begin{align*}
  \int_{a}^{b} |f-g|^2 d\alpha
  =& \sum_{i=1}^n \int_{x_{i-1}}^{x_i} |f-g|^2 d\alpha \\
  \leq& \sum_{i=1}^n \int_{x_{i-1}}^{x_i} (M-m)(M_i - m_i) d\alpha \\
  =& (M-m) \sum_{i=1}^n \int_{x_{i-1}}^{x_i} (M_i - m_i) \Delta \alpha_i \\
  =& (M-m) [ U(P,f,\alpha) - L(P,f,\alpha) ] \\
  \leq& (M-m) \cdot \frac{\varepsilon^2}{M - m + 1} \\
  <& \varepsilon^2.
\end{align*}
Hence,
\[
  \norm{f-g}_2
  = \left\{ \int_{a}^{b} |f-g|^2 d\alpha \right\}^{\frac{1}{2}}
  < \varepsilon.
\]
\end{enumerate}
$\Box$ \\



\emph{Note.}
\begin{enumerate}
\item[(1)]
  Apply the same argument we can prove the following statement:
  \begin{quote}
    \emph{Suppose $f \in \mathscr{R}(\alpha)$ and $\varepsilon > 0$.
    Prove that there exists a continuous function $g$ on $[a,b]$
    such that $\int_{a}^{b} |f-g| d\alpha < \varepsilon$.}
  \end{quote}

\item[(2)]
  (Lebesgue integral)
  \begin{enumerate}
    \item[(a)]
    \emph{Let $f$ be Lebesgue integrable over $E$.
    Then, given $\varepsilon > 0$,
    there is a simple function $\varphi$ such that
    \[
      \int_E |f-\varphi| < \varepsilon.
    \]}

    \item[(b)]
    \emph{Under the same hypothesis there is a step function $\psi$ such that
    \[
      \int_E |f-\psi| < \varepsilon.
    \]}

    \item[(c)]
    \emph{Under the same hypothesis there is a continuous function $g$
    vanishing outside a finite interval such that
    \[
      \int_E |f-g| < \varepsilon.
    \]} \\\\
  \end{enumerate}
\end{enumerate}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\textbf{Exercise 6.13.}
\emph{Define
\[
  f(x) = \int_{x}^{x+1} \sin(t^2)dt.
\]}
\begin{enumerate}
  \item[(a)]
  \emph{Prove that $|f(x)| < \frac{1}{x}$ if $x > 0$.
  (Hint: Put $t^2 = u$ and integrate by parts, to show that $f(x)$ is equal to
  \[
    \frac{\cos(x^2)}{2x} - \frac{\cos[(x+1)^2]}{2(x+1)}
    - \int_{x^2}^{(x+1)^2} \frac{\cos u}{4u^{\frac{3}{2}}} du.
  \]
  Replace $\cos u$ by $-1$.)}

  \item[(b)]
  \emph{Prove that
  \[
    2xf(x) = \cos(x^2) - \cos[(x+1)^2] + r(x)
  \]
  where $|r(x)| < \frac{c}{x}$ and $c$ is a constant.}

  \item[(c)]
  \emph{Find the upper and lower limits of $xf(x)$, as $x \to \infty$.}

  \item[(d)]
  \emph{Does $\int_{0}^{\infty} \sin(t^2)dt$ converges?} \\
\end{enumerate}

\emph{Proof of (a).}
\begin{enumerate}
  \item[(1)]
  Put $t^2 = u$ and integrate by parts to get
  \begin{align*}
    f(x)
    &= \int_{x}^{x+1} \sin(t^2)dt \\
    &= \int_{x^2}^{(x+1)^2} \frac{\sin u}{2u^{\frac{1}{2}}} du \\
    &= - \frac{\cos[(x+1)^2]}{2(x+1)}
      + \frac{\cos(x^2)}{2x}
      - \int_{x^2}^{(x+1)^2} \frac{\cos u}{4u^{\frac{3}{2}}} du.
  \end{align*}

  \item[(2)]
  \begin{align*}
    |f(x)|
    &\leq \abs{ \frac{\cos[(x+1)^2]}{2(x+1)} }
      + \abs{ \frac{\cos(x^2)}{2x} }
      + \abs{ \int_{x^2}^{(x+1)^2} \frac{\cos u}{4u^{\frac{3}{2}}} du } \\
    &\leq \abs{ \frac{\cos[(x+1)^2]}{2(x+1)} }
      + \abs{ \frac{\cos(x^2)}{2x} }
      + \int_{x^2}^{(x+1)^2} \frac{|\cos u|}{4u^{\frac{3}{2}}} du \\
    &\leq \frac{1}{2(x+1)}
      + \frac{1}{2x}
      + \int_{x^2}^{(x+1)^2} \frac{1}{4u^{\frac{3}{2}}} du \\
    &= \frac{1}{2(x+1)}
      + \frac{1}{2x}
      + \left[ \frac{1}{2x} - \frac{1}{2(x+1)} \right] \\
    &= \frac{1}{x}.
  \end{align*}

  \item[(3)]
  The equality in (2) holds only if
  $\abs{ \cos[(x+1)^2] } = 1$, $\abs{ \cos(x^2) } = 1$,
  and
  \[
    \abs{ \int_{x^2}^{(x+1)^2} \frac{\cos u}{4u^{\frac{3}{2}}} du }
    = \int_{x^2}^{(x+1)^2} \frac{\abs{\cos u}}{4u^{\frac{3}{2}}} du
    = \int_{x^2}^{(x+1)^2} \frac{1}{4u^{\frac{3}{2}}} du.
  \]
  Since $\cos u$ has two absolute minimums or maximums at two different points
  $u = x^2$ and $u = (x+1)^2$, by the property of $\cos(u)$ there is some
  $u_0 \in [x^2,(x+1)^2]$ such that $\cos(u_0) = 0$.
  Hence given $\varepsilon = \frac{1}{2} > 0$ there exists $\delta > 0$
  such that
  \[
    |\cos(u)| \leq \frac{1}{2}
  \]
  whenever
  \[
    u \in E = [\max\{u_0-\delta,x^2\},\min\{u_0+\delta,(x+1)^2\}]
    \subseteq [x^2,(x+1)^2].
  \]
  Here $|E| > 0$.
  So that
  \[
    \int_{x^2}^{(x+1)^2} \frac{\abs{\cos u}}{4u^{\frac{3}{2}}} du
    \leq \int_{x^2}^{(x+1)^2} \frac{1}{4u^{\frac{3}{2}}} du
      - \frac{1}{2} \int_{E} \frac{1}{4u^{\frac{3}{2}}} du
    < \int_{x^2}^{(x+1)^2} \frac{1}{4u^{\frac{3}{2}}} du,
  \]
  which is absurd.
  Hence the equality in (2) does not hold.
\end{enumerate}
$\Box$ \\



\emph{Proof of (b).}
\begin{enumerate}
  \item[(1)]
  By (a),
  \[
    2xf(x) = \cos(x^2) - \cos[(x+1)^2] + r(x)
  \]
  where
  \[
    r(x)
    = \frac{\cos[(x+1)^2]}{x+1}
    - 2x\int_{x^2}^{(x+1)^2} \frac{\cos u}{4u^{\frac{3}{2}}} du.
  \]

  \item[(2)]
  Similar to (a),
  \begin{align*}
    |r(x)|
    &\leq \frac{1}{x+1}
      + 2x \int_{x^2}^{(x+1)^2} \frac{1}{4u^{\frac{3}{2}}} du \\
    &= \frac{1}{x+1}
      + 2x \left[ \frac{1}{2x} - \frac{1}{2(x+1)} \right] \\
    &= \frac{2}{x+1} \\
    &< \frac{2}{x}.
  \end{align*}
\end{enumerate}
$\Box$ \\



\emph{Proof of (c).}
\emph{Show that}
\[
  \limsup_{x \to \infty} x f(x) = 1.
\]
The case $\liminf_{x \to \infty} x f(x) = -1$ is similar.
\begin{enumerate}
  \item[(1)]
  By (b), \emph{it suffices to show that}
  \[
    \limsup_{x \to \infty} \left[ \cos(x^2) - \cos(x+1)^2 \right] = 2.
  \]
  Take $x_n = 2n \sqrt{\pi}$ for $n = 1, 2, 3, \ldots$.
  So
  \[
    \cos(x_n^2) - \cos(x_n+1)^2
    = 1 - \cos(4n\sqrt{\pi} + 1).
  \]
  \emph{It suffices to show that}
  \[
    \liminf_{n \to \infty} \cos(4n\sqrt{\pi} + 1) = -1.
  \]

  \item[(2)]
  $x \mapsto \cos(x)$ is uniformly continuous by the mean value theorem (Theorem 5.10)
  and $x \mapsto -\sin(x)$ is bounded by $1$.
  So given any $\varepsilon > 0$, there exists $\delta > 0$
  such that $\abs{ \cos(x) - \cos(y) } < \varepsilon$
  whenever $|x-y| < \delta$

  \item[(3)]
  Define $\alpha = \frac{1}{\sqrt{\pi}}$ and $x = \frac{\pi-1}{4\pi}$.
  Note that $\pi$ is irrational and thus $\alpha$ is irrational.
  (See
  \href{https://en.wikipedia.org/wiki/Proof_that_%CF%80_is_irrational}{Wikipedia}
  for the irrationality of $\pi$.)
  Exercise 4.25(b) implies that
  there exist integers $n > 0$ and $m$ such that
  \[
    \abs{ n \alpha - m - x } < \frac{\delta}{4\pi},
  \]
  or
  \[
    \abs{ (4n\sqrt{\pi} + 1) - (4m\pi - \pi) } < \delta.
  \]
  By (2),
  \[
    \abs{ \cos(4n\sqrt{\pi} + 1) - (-1) } < \varepsilon.
  \]
  Hence $\liminf_{n \to \infty} \cos(4n\sqrt{\pi} + 1) = -1$.

\end{enumerate}
$\Box$ \\



\emph{Proof of (d).}
Yes. $\int_{0}^{\infty} \sin(t^2) dt$ converges.
\begin{enumerate}
  \item[(1)]
  Given any integer $N > 0$.
  Write
  \begin{align*}
    \int_{0}^{N} \sin(t^2) dt
    &= \sum_{n=0}^{N-1} \int_{n}^{n+1} \sin(t^2) dt \\
    &= \sum_{n=0}^{N-1} f(n) \\
    &= f(0)
      + \sum_{n=1}^{N-1}
      \frac{\cos(n^2)}{2n} - \frac{\cos[(n+1)^2]}{2n} + \frac{r(n)}{2n} \\
    &= f(0)
      + \sum_{n=1}^{N-1} \frac{\cos(n^2)}{2n}
      - \sum_{n=1}^{N-1} \frac{\cos[(n+1)^2]}{2n}
      + \sum_{n=1}^{N-1} \frac{r(n)}{2n} \\
    &= f(0)
      + \sum_{n=1}^{N-1} \frac{\cos(n^2)}{2n}
      - \sum_{n=2}^{N} \frac{\cos(n^2)}{2(n-1)}
      + \sum_{n=1}^{N-1} \frac{r(n)}{2n} \\
    &= f(0) + \frac{\cos(1)}{2} - \frac{\cos(N^2)}{2(N-1)}
      - \frac{1}{2} \sum_{n=2}^{N-1} \frac{\cos(n^2)}{n(n-1)}
      + \sum_{n=1}^{N-1} \frac{r(n)}{2n}
  \end{align*}
  where $|r(n)| \leq \frac{2}{n}$ (by (b)).

  \item[(2)]
  $\frac{\cos(N^2)}{2(N-1)} \to 0$ as $N \to \infty$
  since $\cos(N^2)$ is bounded by $1$ and $\frac{1}{N-1} \to 0$ as $N \to \infty$.

  \item[(3)]
  Since $\cos(n^2)$ is bounded by $1$ and
  $\sum \frac{1}{n(n-1)} < \sum \frac{1}{(n-1)^2}$ converges,
  \[
    \frac{1}{2} \sum_{n=2}^{\infty} \frac{\cos(n^2)}{n(n-1)}
  \]
  converges absolutely.

  \item[(4)]
  Since $|r(n)| \leq \frac{2}{n}$ and
  $\sum \frac{1}{n^2}$ converges,
  \[
    \sum_{n=1}^{\infty} \frac{|r(n)|}{2n}
    \leq \sum_{n=1}^{\infty} \frac{1}{n^2}
  \]
  converges.
  So $\sum_{n=1}^{\infty} \frac{r(n)}{2n}$ converges absolutely.

  \item[(5)]
  By (1)(2)(3)(4),
  \[
    \lim_{N \to \infty} \int_{0}^{N} \sin(t^2) dt
  \]
  exists.
  Note that
  \[
    \abs{ \int_{x}^{y} \sin(t^2) dt } < \frac{1}{x}
  \]
  if $y \geq x > 0$ (by applying the same argument in (a)(2)).
  So
  \[
    \lim_{\substack{x \to \infty \\ y \to \infty \\ y \geq x}}
      \int_{x}^{y} \sin(t^2) dt = 0.
  \]
  Therefore,
  \begin{align*}
    \int_{0}^{\infty} \sin(t^2) dt
    &= \lim_{b \to \infty} \int_{0}^{b} \sin(t^2) dt \\
    &= \lim_{b \to \infty} \int_{0}^{[b]} \sin(t^2) dt + \int_{[b]}^{b} \sin(t^2) dt \\
    &= \lim_{b \to \infty} \int_{0}^{[b]} \sin(t^2) dt
      + \lim_{b \to \infty} \int_{[b]}^{b} \sin(t^2) dt \\
    &= \lim_{N \to \infty} \int_{0}^{N} \sin(t^2) dt
      + \lim_{\substack{[b] \to \infty \\ b \to \infty \\ b \geq [b]}}
        \int_{[b]}^{b} \sin(t^2) dt \\
    &= \lim_{N \to \infty} \int_{0}^{N} \sin(t^2) dt
  \end{align*}
  converges.
\end{enumerate}
$\Box$ \\



\emph{Note.}
\[
  \int_{0}^{\infty} \sin(t^2)dt
  = \int_{0}^{\infty} \cos(t^2)dt
  = \frac{\sqrt{\pi}}{2\sqrt{2}}.
\] \\\\



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\textbf{Exercise 6.14.}
\emph{Deal similarly with
\[
  f(x) = \int_{x}^{x+1} \sin(e^t) dt.
\]
Show that
\[
  e^x|f(x)| < 2
\]
and that
\[
  e^x f(x) = \cos(e^x) - e^{-1} \cos(e^{x+1}) + r(x)
\]
where $|r(x)| < Ce^{-x}$ for some constant $C$.} \\



\emph{Proof.}
\begin{enumerate}
  \item[(1)]
  Put $e^t = u$ and integrate by parts to get
  \begin{align*}
    f(x)
    &= \int_{x}^{x+1} \sin(e^t)dt \\
    &= \int_{\exp(x)}^{\exp(x+1)} \frac{\sin u}{u} du \\
    &= - \frac{\cos(e^{x+1})}{e^{x+1}}
      + \frac{\cos(e^x)}{e^x}
      - \int_{\exp(x)}^{\exp(x+1)} \frac{\cos u}{u^2} du.
  \end{align*}

  \item[(2)]
  \emph{Show that $e^x|f(x)| \leq 2$.}
  \begin{align*}
    |f(x)|
    &\leq \abs{ \frac{\cos(e^{x+1})}{e^{x+1}} }
      + \abs{ \frac{\cos(e^x)}{e^x} }
      + \abs{ \int_{\exp(x)}^{\exp(x+1)} \frac{\cos u}{u^2} du } \\
    &\leq \abs{ \frac{\cos(e^{x+1})}{e^{x+1}} }
      + \abs{ \frac{\cos(e^x)}{e^x} }
      + \int_{\exp(x)}^{\exp(x+1)} \frac{|\cos u|}{u^2} du \\
    &\leq \frac{1}{e^{x+1}}
      + \frac{1}{e^x}
      + \int_{\exp(x)}^{\exp(x+1)} \frac{1}{u^2} du \\
    &= \frac{1}{e^{x+1}}
      + \frac{1}{e^x}
      + \left[ \frac{1}{e^x} - \frac{1}{e^{x+1}} \right] \\
    &= \frac{2}{e^x}.
  \end{align*}
  Hence $e^x|f(x)| \leq 2$.

  \item[(3)]
  \emph{Show that $e^x|f(x)| < 2$.}
  Similar to (b)(3) in the proof of Exercise 6.13.

  \item[(4)]
  \emph{Show that
  \[
    e^x f(x) = \cos(e^x) - e^{-1} \cos(e^{x+1}) + r(x)
  \]
  where $|r(x)| < Ce^{-x}$ for some constant $C$.}
  By (1),
  \[
    e^x f(x) = \cos(e^x) - e^{-1}\cos(e^{x+1})
      - e^x \int_{\exp(x)}^{\exp(x+1)} \frac{\cos u}{u^2} du.
  \]
  So that
  \[
    r(x) = - e^x \int_{\exp(x)}^{\exp(x+1)} \frac{\cos u}{u^2} du.
  \]
  By integration by parts (Theorem 6.22),
  \begin{align*}
    \int_{\exp(x)}^{\exp(x+1)} \frac{\cos u}{u^2} du
    &= \left[ \frac{\sin u}{u^2} \right]_{u=\exp(x)}^{u=\exp(x+1)}
      - \int_{\exp(x)}^{\exp(x+1)} \frac{-2 \sin u}{u^3} du \\
    &= \frac{\sin e^{x+1}}{e^{2x+2}} - \frac{\sin e^{x}}{e^{2x}}
      + 2 \int_{\exp(x)}^{\exp(x+1)} \frac{\sin u}{u^3} du.
  \end{align*}
  So that
  \begin{align*}
    |r(x)|
    &\leq \abs{ \frac{\sin e^{x+1}}{e^{x+2}} }
      + \abs{ \frac{\sin e^{x}}{e^{x}} }
      + 2 e^x \int_{\exp(x)}^{\exp(x+1)} \frac{\abs{\sin u}}{u^3} du \\
    &\leq \frac{1}{e^{x+2}}
      + \frac{1}{e^{x}}
      + 2 e^x \int_{\exp(x)}^{\exp(x+1)} \frac{du}{u^3} \\
    &= \frac{1}{e^{x+2}}
      + \frac{1}{e^{x}}
      + 2 e^x \left[ -\frac{1}{2} u^{-2} \right]_{u=\exp(x)}^{u=\exp(x+1)} \\
    &= \frac{2}{e^{x}}.
  \end{align*}
  The equality does not hold as in (3), or $|r(x)| < 2 e^{-x}$.

  \item[(5)]
  \emph{Show that $\int_{0}^{\infty} \sin(e^t) dt$ converges.}
  Similar to (d) in Exercise 6.13.
  Given any integer $N > 0$, write
  \[
    \int_{0}^{N} \sin(e^t) dt
    = f(0) + \frac{\cos(e)}{e} - \underbrace{\frac{\cos(e^N)}{e^N}}_{\to 0}
      + \underbrace{\sum_{n=1}^{N-1} \frac{r(n)}{e^n}}_{< \infty}
  \]
  where $|r(n)| \leq \frac{2}{e^n}$ (by (4)).
  So $\lim \int_{0}^{N} \sin(e^t) dt$ exists.
  Also note that
  \[
    \abs{ \int_{x}^{y} \sin(e^t) dt } < \frac{2}{e^x}
  \]
  if $y \geq x > 0$ (by applying the same argument in (2)).
  Therefore
  \[
    \int_{0}^{\infty} \sin(e^t) dt
    = \lim_{b \to \infty} \int_{0}^{b} \sin(e^t) dt
    = \lim_{N \to \infty} \int_{0}^{N} \sin(e^t) dt
  \]
  converges.
\end{enumerate}
$\Box$ \\



\emph{Note.}
Similar to Exercise 6.13(c), we have
\[
  \limsup_{x \to \infty} e^x f(x) = 1 + e^{-1}
\]
and
\[
  \liminf_{x \to \infty} e^x f(x) = -1-e^{-1}
\]
by the fact that $e$ is irrational (Theorem 3.32). \\\\



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\textbf{Exercise 6.15.}
\emph{Suppose $f$ is a real, continuously differentiable function on $[a,b]$,
$f(a)=f(b)=0$, and
\[
  \int_{a}^{b} f(x)^2 dx = 1.
\]
Prove that
\[
  \int_{a}^{b} xf(x)f'(x) dx = -\frac{1}{2}
\]
and that
\[
  \int_{a}^{b} [f'(x)]^2 dx \int_{a}^{b} x^2f(x)^2 dx > \frac{1}{4}.
\]
} \\

\emph{Proof.}
Every integral is well-defined (Theorem 4.9 and Theorem 6.8).
\begin{enumerate}
  \item[(1)]
  By Theorem 6.22 (integration by parts),
  \[
    \int_{a}^{b} x \left( \frac{f(x)^2}{2} \right)' dx
    =
    \left[ x \cdot \frac{f(x)^2}{2} \right]_{x=a}^{x=b}
      - \int_{a}^{b} \frac{f(x)^2}{2} dx,
  \]
  or
  \[
    \int_{a}^{b} xf(x)f'(x) dx
    =
      \left[b \cdot \frac{f(b)^2}{2} - a \cdot \frac{f(a)^2}{2} \right]
      - \frac{1}{2} \int_{a}^{b} f(x)^2 dx
    = - \frac{1}{2}.
  \]

  \item[(2)]
  By Exercise 6.10(c),
  \[
    \int_{a}^{b} [f'(x)]^2 dx \int_{a}^{b} x^2f(x)^2 dx
    \geq \left( \int_{a}^{b} xf(x)f'(x) dx \right)^2 = \frac{1}{4}.
  \]

  \item[(3)]
  (Reductio ad absurdum)
  If the equality were holding, then by Exercise 6.10(c)
  \[
    (f'(x))^2 \int_{a}^{b} x^2f(x)^2 dx
    = x^2f(x)^2 \int_{a}^{b} [f'(x)]^2 dx
  \]
  on $[a,b]$
  (since $x$, $f(x)$ and $f'(x)$ are continuous on $[a,b]$).

  \begin{enumerate}
  \item[(a)]
    \emph{Show that both integrals are nonzero.}
    (Reductio ad absurdum)
    If $\int_{a}^{b} x^2f(x)^2 dx = 0$,
    then $x^2f(x)^2 = 0$ or $xf(x) = 0$ on $[a,b]$ (Exercise 6.2).
    So that
    \[
      \int_{a}^{b} xf(x)f'(x) dx = 0 \neq -\frac{1}{2},
    \]
    which is absure.
    Similarly, $\int_{a}^{b} [f'(x)]^2 dx \neq 0$.

  \item[(b)]
    By (a), we write
    \[
      C
      =
      \left\{ \frac{\int_{a}^{b} [f'(x)]^2 dx}{\int_{a}^{b} x^2f(x)^2 dx} \right\}^{\frac{1}{2}}
      > 0
    \]
    be a positive constant.
    Hence
    \[
      f'(x) = \pm C x f(x).
    \]
    Here the sign ``$\pm$'' is not necessary unchanged on $[a,b]$.
    Luckily, we can show that the sign ``$\pm$'' is unchanged on some subinterval of $[a,b]$.

  \item[(c)]
    To find such subinterval of $[a,b]$,
    we consider the zero set $Z(f')$ and $Z(xf)$ on $[a,b]$.
    Since $f'(x) = \pm C x f(x)$ with $C > 0$, we have
    \[
      Z(f') = Z(xf).
    \]
    Note that $Z(f') = Z(xf)$ is closed (Exercise 4.3) and not equal to $[a,b]$
    (by applying the same argument in (a)).
    Hence the complement of $Z(f') = Z(xf)$ is open and nonempty,
    which can be written as the union of an at most countable collection
    of disjoint segments (Exercise 2.29).

  \item[(d)]
    Consider any nonempty open interval in (c), say
    \[
      (c,d) \subseteq [a,b].
    \]
    By construction, $f'(x) \neq 0$ for all $x \in (c,d)$.
    Since $f'(x)$ is continuous, by Theorem 4.23
    there are only two mutually exclusive possible cases:
    \begin{enumerate}
      \item[(i)]
      $f'(x) > 0$ for all $x \in (c,d)$,

      \item[(ii)]
      $f'(x) < 0$ for all $x \in (c,d)$.
    \end{enumerate}
    Similar result for $xf(x)$.
    Therefore, the sign ``$\pm$'' of $f'(x) = \pm C x f(x)$ are unchanged on $(c,d)$,
    that is,
    \begin{enumerate}
      \item[(i)]
      $f'(x) = C x f(x)$ for all $x \in (c,d)$,

      \item[(ii)]
      $f'(x) = -C x f(x)$ for all $x \in (c,d)$,
    \end{enumerate}

  \item[(e)]
    Suppose $f'(x) = C xf(x)$ on $(c,d)$.
    Since $f'(x)$ and $xf(x)$ are both vanishing at $x = c$ and $x = d$,
    $f'(x) = C xf(x)$ at $x = c$ and $x = d$.
    So
    \[
      f'(x) = C xf(x) \:\text{ if }\: x \in [c,d].
    \]
    Define
    \[
      \phi(x,y) = Cxy
    \]
    be a real function on $R = [c,d] \times \mathbb{R}$.
    And consider the initial-value problem
    \[
      y' = \phi(x,y)
      \qquad
      \text{ with }
      \qquad
      y(c) = 0.
    \]
    Then
    \[
      |\phi(x,y_2) - \phi(x,y_1)|
      = Cx|y_2-y_1|
      \leq A|y_2-y_1|
    \]
    where $A = C \cdot \max\{|c|,|d|\}$ is a constant.
    By Exercise 5.27, this initial-value problem has at most one solution.
    Clearly, $y = f(x) = 0$ on $[c,d]$ is one solution of this initial-value problem,
    contrary to the construction of $[c,d]$.
    Similar result for the case $f'(x) = -C xf(x)$.
  \end{enumerate}
  Therefore, the equality does not hold.
\end{enumerate}
$\Box$ \\\\



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\textbf{Exercise 6.16.}
\emph{For $1 < s < \infty$, define
\[
  \zeta(s) = \sum_{n=1}^{\infty} \frac{1}{n^s}.
\]
(This is Riemann's zeta function, of great importance in the study of the
distribution of prime numbers.)
Prove that}
\begin{enumerate}
  \item[(a)]
  \[
    \zeta(s) = s \int_{1}^{\infty} \frac{[x]}{x^{s+1}} dx
  \]
\end{enumerate}
\emph{and that}
\begin{enumerate}
  \item[(b)]
  \[
    \zeta(s) = \frac{s}{s-1} - s \int_{1}^{\infty} \frac{x - [x]}{x^{s+1}} dx,
  \]
\end{enumerate}
\emph{where $[x]$ denotes the greatest integer $\leq x$.
Prove that the integral in (b) converges for all $s > 0$.
(Hint: To prove (a), compute the difference between the integral over $[1,N]$
and the $N$th partial sum of the series that defines $\zeta(s)$.)} \\

\emph{Proof of (a) (Hint).}
\begin{enumerate}
  \item[(1)]
  Define
  \[
    a_N = s \int_{1}^{N} \frac{[x]}{x^{s+1}} dx - \sum_{n=1}^{N} \frac{1}{n^s}.
  \]
  Hence
  \begin{align*}
    s \int_{1}^{N} \frac{[x]}{x^{s+1}} dx
    &=
    \sum_{n=1}^{N-1} s \int_{n}^{n+1} \frac{[x]}{x^{s+1}} dx \\
    &=
    \sum_{n=1}^{N-1} s \int_{n}^{n+1} \frac{n}{x^{s+1}} dx \\
    &=
    \sum_{n=1}^{N-1} n \left( \frac{1}{n^s} - \frac{1}{(n+1)^s} \right) \\
    &=
    \left( \sum_{n=1}^N \frac{1}{n^s} \right) - \frac{1}{N^{s-1}},
  \end{align*}
  or
  \[
    a_N = -\frac{1}{N^{s-1}}.
  \]

  \item[(2)]
  So
  \[
    \lim_{N \to \infty} a_N = 0
  \]
  (since $s - 1 > 0$).
  By Theorem 3.28, $\zeta(s)$ converges if $s > 1$.
  Hence
  \[
    \lim_{N \to \infty} s \int_{1}^{N} \frac{[x]}{x^{s+1}} dx = \zeta(s)
  \]
  converges.

  \item[(3)]
  Hence given any real $b > 1$, there exists an integer $N$ such that $N \leq b < N+1$.
  Since $x \mapsto \frac{[x]}{x^{s+1}} \geq 0$ on $[1,\infty)$,
  \[
    s \int_{1}^{N} \frac{[x]}{x^{s+1}} dx
    \leq
    s \int_{1}^{b} \frac{[x]}{x^{s+1}} dx
    \leq
    s \int_{1}^{N+1} \frac{[x]}{x^{s+1}} dx.
  \]
  Since $b \to \infty$ if and only if $N \to \infty$,
  \begin{align*}
    &\lim_{N \to \infty} s \int_{1}^{N} \frac{[x]}{x^{s+1}} dx
      \leq
      \lim_{b \to \infty} s \int_{1}^{b} \frac{[x]}{x^{s+1}} dx
      \leq
      \lim_{N \to \infty} s \int_{1}^{N+1} \frac{[x]}{x^{s+1}} dx \\
    \Longrightarrow&
      \zeta(s)
      \leq
      \lim_{b \to \infty} s \int_{1}^{b} \frac{[x]}{x^{s+1}} dx
      \leq
      \zeta(s).
  \end{align*}
  Hence
  \[
    \lim_{b \to \infty} s \int_{1}^{b} \frac{[x]}{x^{s+1}} dx
    = s \int_{1}^{\infty} \frac{[x]}{x^{s+1}} dx
    = \zeta(s)
  \]
  (in the sense of Exercise 6.8).
\end{enumerate}
$\Box$ \\



\emph{Proof of (b).}
\begin{enumerate}
  \item[(1)]
  \emph{Show that}
  \[
    s \int_{1}^{\infty} \frac{1}{x^{s}} dx = \frac{s}{s-1}.
  \]
  Given any real $b > 1$. By the fundamental theorem of calculus (Theorem 6.21),
  \[
    s \int_{1}^{b} \frac{1}{x^{s}} dx
    = \frac{s}{s-1} - \frac{s}{(s-1)b^{s-1}}.
  \]
  Hence
  \[
    \lim_{b \to \infty} s \int_{1}^{b} \frac{1}{x^{s}} dx = \frac{s}{s-1}
  \]
  since $\frac{1}{b^{s-1}} \to 0$ as $b \to \infty$ (in the sense of Exercise 6.8).

  \item[(2)]
  By (a) and (1),
  $s \int_{1}^{\infty} \frac{x - [x]}{x^{s+1}} dx$ exists
  and equal to
  \[
    s \int_{1}^{\infty} \frac{x - [x]}{x^{s+1}} dx
    = s \int_{1}^{\infty} \frac{1}{x^{s}} dx - s \int_{1}^{\infty} \frac{[x]}{x^{s+1}} dx
    = \frac{s}{s-1} - \zeta(s).
  \]
  The result is established.

  \item[(3)]
  \emph{Show that
  \[
    \int_{1}^{\infty} \frac{x - [x]}{x^{s+1}} dx
  \]
  converges for all $s > 0$.}
  Note that $0 \leq x - [x] < 1$ on $[1,\infty)$.
  So
  \[
    \int_{1}^{b} \frac{x - [x]}{x^{s+1}} dx
    \leq
    \int_{1}^{b} \frac{1}{x^{s+1}} dx
    = \frac{1}{s} - \frac{1}{sb^s}.
  \]
  Since $\frac{1}{sb^{s}} \to 0$ as $b \to \infty$,
  \[
    \int_{1}^{\infty} \frac{x - [x]}{x^{s+1}} dx
    = \lim_{b \to \infty} \int_{1}^{b} \frac{x - [x]}{x^{s+1}} dx
    \leq \lim_{b \to \infty} \frac{1}{s} - \frac{1}{sb^s}
    = \frac{1}{s}.
  \]
  Note that $\frac{1}{s}$ is finite, and thus
  the integral $\int_{1}^{\infty} \frac{x - [x]}{x^{s+1}} dx$
  converges.
\end{enumerate}
$\Box$ \\



\emph{Note.}
\begin{enumerate}
\item[(1)]
The integral
$\int_{1}^{\infty} \frac{[x]}{x^{s+1}} dx$ does not converge for all $1 \geq s > 0$.

\item[(2)]
Compare to Exercise 8.9.

\item[(3)]
\textbf{Euler's summation formula.}
(Theorem 7.13 in the textbook:
\emph{Tom. M. Apostol, Mathematical Analysis, 2nd edition.})
\emph{If $f$ has a continuous derivative $f'$ on $[a,b]$, then we have
\[
  \sum_{a < n \leq b} f(n)
  = \int_{a}^{b} f(x)dx
  + \int_{a}^{b} f'(x)\{x\}dx + f(a)\{a\} - f(b)\{b\},
\]
where $\sum_{a < n \leq b}$ means the sum from $n=[a]+1$ to $n=[b]$.
When $a$ and $b$ are integers, this becomes}
\[
  \sum_{n=a}^{b} f(n)
  = \int_{a}^{b} f(x)dx
  + \int_{a}^{b} f'(x)\left( \{x\}-\frac{1}{2} \right)dx
  + \frac{f(a)+f(b)}{2}.
\]
By taking $f(x) = \frac{1}{x^s}$ we can get (a) as well. \\\\
\end{enumerate}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\textbf{Exercise 6.17.}
\emph{Suppose $\alpha$ increases monotonically on $[a,b]$,
$g$ is continuous,
and $g(x) = G'(x)$ for $a \leq x \leq b$.
Prove that
\[
  \int_{a}^{b} \alpha(x)g(x)dx
  = G(b)\alpha(b) - G(a)\alpha(a) - \int_{a}^{b}G d\alpha.
\]
(Hint: Take $g$ real, without loss of generality.
Given $P = \{a = x_0, x_1, \ldots, x_n = b\}$,
choose $t_i \in (x_{i-1},x_i)$ so that $g(t_i)\Delta x_i = G(x_i) - G(x_{i-1})$.
Show that
\[
  \sum_{i=1}^{n} \alpha(x_i)g(t_i)\Delta x_i
  = G(b)\alpha(b) - G(a)\alpha(a) - \sum_{i=1}^{n} G(x_{i-1})\Delta \alpha_i.)
\]} \\

\emph{Proof (Hint).}
Given $\varepsilon > 0$.
\begin{enumerate}
  \item[(1)]
  Take $g$ real, without loss of generality.
  Given any partition
  \[
    P = \{a = x_0 < x_1 < \ldots < x_n = b\}
  \]
  of $[a,b]$.

  \item[(2)]
  By the mean value theorem (Theorem 5.10), there is $t_i \in (x_{i-1},x_i)$
  such that
  \[
    G(x_i) - G(x_{i-1}) = (x_i - x_{i-1})G'(t_i) = g(t_i)\Delta x_i.
  \]

  \item[(3)]
  Hence,
  \begin{align*}
    \sum_{i=1}^{n} \alpha(x_i)g(t_i)\Delta x_i
    &= \sum_{i=1}^{n} \alpha(x_i)(G(x_i) - G(x_{i-1})) \\
    &= \sum_{i=1}^{n} \alpha(x_i)G(x_i) - \sum_{i=1}^{n} \alpha(x_i)G(x_{i-1}) \\
    &= \underbrace{G(b)\alpha(b) - G(a)\alpha(a)
      + \sum_{i=1}^{n} \alpha(x_{i-1})G(x_{i-1})}_{\text{
        adjust the index of $\sum_{i=1}^{n} \alpha(x_i)G(x_i)$}}
      - \sum_{i=1}^{n} \alpha(x_i)G(x_{i-1}) \\
    &= G(b)\alpha(b) - G(a)\alpha(a) - \sum_{i=1}^{n} G(x_{i-1}) \Delta\alpha_i.
  \end{align*}

  \item[(4)]
  Since $G(x)$ is differentiable on $[a,b]$,
  $G(x)$ is continuous (Theorem 5.2) and thus $G \in \mathscr{R}(\alpha)$ (Theorem 6.8).
  So there is a partition $P_1$ such that
  \[
    \abs{\sum_{j=1}^{n} G(t_j)\Delta\alpha_j - \int_{a}^{b}G d\alpha }
    < \varepsilon
  \]
  whenever $t_j \in [x_{j-1},x_j]$ (Theorem 6.7).
  In particular, we pick $t_j = x_{j-1} \in [x_{j-1},x_j]$ for all $j$, that is,
  \[
    \abs{\sum_{j=1}^{n} G(x_{j-1})\Delta\alpha_j - \int_{a}^{b}G d\alpha }
    < \varepsilon.
  \]
  Note that if $P^{*}$ is a refinement of $P$, the result is true too (Theorem 6.4).

  \item[(5)]
  Since $\alpha$ increases monotonically, $\alpha \in \mathscr{R}$ (Theorem 6.9).
  Since $g$ is continuous, $g \in \mathscr{R}$ (Theorem 6.8).
  Hence $\alpha g \in \mathscr{R}$ (Theorem 6.13).
  So there is a partition $P_2$ such that
  \[
    \abs{\sum_{k=1}^{m} \alpha(t_k)g(t_k) \Delta x_k - \int_{a}^{b} \alpha g dx }
    < \varepsilon
  \]
  whenever $t_k \in [x_{k-1},x_k]$ (Theorem 6.7).
  In particular, we pick $t_k = x_k \in [x_{k-1},x_k]$ for all $k$, that is,
  \[
    \abs{\sum_{k=1}^{m} \alpha(x_k)g(x_k) \Delta x_k - \int_{a}^{b} \alpha g dx }
    < \varepsilon.
  \]
  Note that if $P^{*}$ is a refinement of $P$, the result is true too (Theorem 6.4).

  \item[(6)]
  Since $g$ is continuous on a compact set $[a,b]$,
  $g$ is uniformly continuous.
  Hence there exists $\delta > 0$ such that
  \[
    |g(y) - g(x)| < \varepsilon
  \]
  whenever $|y - x| < \delta$ and $x, y \in [a,b]$.
  For such $\delta$, we construct a partition $P_3$ such that
  \[
    |g(t_l) - g(x_l)| < \varepsilon
  \]
  whenever $t_l \in [x_{l-1},x_l]$.
  (For example, we might take
  \[
    P_3 = \left\{
      a, a + \frac{1}{N}(b-a), a + \frac{2}{N}(b-a), \ldots,
      a + \frac{N-1}{N}(b-a), b
    \right\}
  \]
  where $N$ is an integer $\geq \frac{b-a}{\delta}$.)
  Hence
  \begin{align*}
    &\abs{ \sum_{l=1}^{N} \alpha(x_l)g(t_l) \Delta x_l
      - \sum_{l=1}^{N} \alpha(x_l)g(x_l) \Delta x_l } \\
    =&
    \abs{ \sum_{l=1}^{N} \alpha(x_l)[g(t_l)-g(x_l)] \Delta x_l } \\
    \leq&
    \sum_{l=1}^{N} |\alpha(x_l)| \cdot |g(t_l)-g(x_l)| \cdot \Delta x_l \\
    \leq&
    M \varepsilon \sum_{l=1}^{N} \Delta x_l \\
    =&
    M(b-a) \varepsilon.
  \end{align*}
  Note that if $P^{*}$ is a refinement of $P$, the result is true too
  (by the uniformly convergence of $g$).

  \item[(7)]
  Let $P = \{a = x_0 < x_1 < \ldots < x_n = b\}$
  be a common refinement of $P_1$, $P_2$ and $P_3$.
  By (3)(4)(5)(6) we have
  \begin{align*}
    &\abs{ \int_{a}^{b} \alpha(x)g(x)dx
      - G(b)\alpha(b) + G(a)\alpha(a) + \int_{a}^{b}G d\alpha } \\
    =& \abs{
      \int_{a}^{b} \alpha(x)g(x)dx - \sum_{i=1}^{n} \alpha(x_i)g(t_i)\Delta x_i
      +
      \int_{a}^{b}G d\alpha - \sum_{i=1}^{n} G(x_{i-1}) \Delta\alpha_i } \\
    \leq& \abs{
      \int_{a}^{b} \alpha(x)g(x)dx - \sum_{i=1}^{n} \alpha(x_i)g(t_i)\Delta x_i }
      +
      \abs{ \int_{a}^{b}G d\alpha - \sum_{i=1}^{n} G(x_{i-1}) \Delta\alpha_i } \\
    \leq& \abs{
      \int_{a}^{b} \alpha(x)g(x)dx - \sum_{i=1}^{n} \alpha(x_i)g(x_i)\Delta x_i }
      +
      \abs{ \sum_{i=1}^{n} \alpha(x_i)g(x_i)\Delta x_i
        - \sum_{i=1}^{n} \alpha(x_i)g(t_i)\Delta x_i } \\
      &+
      \abs{ \int_{a}^{b}G d\alpha - \sum_{i=1}^{n} G(x_{i-1}) \Delta\alpha_i } \\
    \leq& \varepsilon + M(b-a)\varepsilon + \varepsilon \\
    =& (M(b-a) + 2)\varepsilon.
  \end{align*}
  Since $\varepsilon$ is arbitrary,
  \[
    \abs{ \int_{a}^{b} \alpha(x)g(x)dx
      - G(b)\alpha(b) + G(a)\alpha(a) + \int_{a}^{b}G d\alpha }=0,
  \]
  or
  \[
    \int_{a}^{b} \alpha(x)g(x)dx
      - G(b)\alpha(b) + G(a)\alpha(a) + \int_{a}^{b}G d\alpha = 0,
  \]
  or
  \[
    \int_{a}^{b} \alpha(x)g(x)dx
    = G(b)\alpha(b) - G(a)\alpha(a) - \int_{a}^{b}G d\alpha.
  \]
\end{enumerate}
$\Box$ \\\\



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\textbf{Exercise 6.18.}
\emph{Let $\gamma_1$, $\gamma_2$, $\gamma_3$ be curves in the complex plane,
defined on $[0,2\pi]$ by
\begin{align*}
  \gamma_1 &= \exp(it), \\
  \gamma_2 &= \exp(2it), \\
  \gamma_3 &= \exp(2\pi it \sin(\frac{1}{t})).
\end{align*}
Show that these three curves have the same range,
that $\gamma_1$ and $\gamma_2$ are rectifiable,
that the length of $\gamma_1$ is $2\pi$,
that the length of $\gamma_2$ is $4\pi$,
and that $\gamma_3$ is not rectifiable.} \\

Might assume that $\gamma_3(0) = 1$. \\



\emph{Proof.}
Write $S^1 = \{ z \in \mathbb{C} : |z| = 1 \}$.
\begin{enumerate}
  \item[(1)]
  \emph{Show that $\gamma_1$ has the range $S^1$.}
  Given any $z \in S^1$.
  Theorem 8.7(d) implies that there is a unique $t \in [0,2\pi)$
  such that $\exp(it) = z$.

  \item[(2)]
  \emph{Show that $\gamma_1$ is rectifiable and its length is $2\pi$.}
  By the definition of $\exp(z)$,
  \[
    \gamma_1'(t) = i\exp(it),
  \]
  which is continuous on $[0,2\pi]$.
  Hence $\gamma_1$ is rectifiable is rectifiable, and its length is
  \[
    \Lambda(\gamma_1)
    = \int_{0}^{2\pi}|\gamma_1'(t)|dt
    = \int_{0}^{2\pi} dt
    = 2\pi
  \]
  (Theorem 6.27).

  \item[(3)]
  \emph{Show that $\gamma_2$ has the range $S^1$.}
  Similar to (1).
  Given any $z \in S^1$.
  Theorem 8.7(d) implies that there is a unique $t \in [0,2\pi)$
  such that $\exp(it) = z$.
  Write $\exp(it) = \exp(2i\left(\frac{t}{2}\right))$
  where $\frac{t}{2} \in [0,\pi) \subseteq [0,2\pi)$.

  \item[(4)]
  \emph{Show that $\gamma_2$ is rectifiable and its length is $4\pi$.}
  Similar to (2).
  \[
    \gamma_2'(t) = 2i\exp(2it),
  \]
  and
  \[
    \Lambda(\gamma_2)
    = \int_{0}^{2\pi}|\gamma_2'(t)|dt
    = \int_{0}^{2\pi} 2 dt
    = 4\pi.
  \]

  \item[(5)]
  \emph{Show that $\gamma_3$ has the range $S^1$.}
  Define
  \begin{equation*}
  f(t) =
    \begin{cases}
      0
      & (t = 0), \\
      t \sin\frac{1}{t}
      & (t \neq 0).
    \end{cases}
  \end{equation*}
  It suffices to show that $f(I) \supseteq J$
  for for some segment $I \subseteq [0,2\pi]$ and
  some segment $J$ in $\mathbb{R}$ of the length $\geq 1$ (Theorem 8.7(a)).
  Define $I = \left[\frac{6}{7\pi}, \frac{6}{\pi} \right] \subseteq [0,2\pi]$
  and $J = \left[-\frac{3}{7\pi}, \frac{3}{\pi} \right]$ of the length $\frac{24}{7\pi} > 1$.
  Hence $f(I)$ is connected since $I$ is connected (Theorem 4.22).
  Since
  \begin{align*}
    f\left(\frac{6}{7\pi}\right) &= \frac{6}{7\pi} \sin\frac{7\pi}{6} = -\frac{3}{7\pi}, \\
    f\left(\frac{6}{\pi}\right) &= \frac{6}{\pi} \sin\frac{\pi}{6} = \frac{3}{\pi},
  \end{align*}
  $f(I) \supseteq J$ (Theorem 2.47).
  The result is established.

  \item[(6)]
  \emph{Show that $\gamma_3$ is not rectifiable.}
  \begin{enumerate}
    \item[(a)]
    Since
    \[
      \gamma_3'
      = 2\pi i \left(\sin\frac{1}{t} - \frac{1}{t}\cos\frac{1}{t} \right)
        \exp(2\pi it \sin(\frac{1}{t}))
    \]
    is continuous on $[c,2\pi]$ for any $c > 0$,
    $\gamma_3$ is rectifiable on $[c,2\pi]$ (not on $[0,2\pi]$),
    and
    \[
      \Lambda_{[c,2\pi]}(\gamma_3)
      = \int_{c}^{2\pi} |\gamma_3'(t)| dt
    \]
    on $[c,2\pi]$.

    \item[(b)]
    \begin{align*}
      \int_{c}^{2\pi} |\gamma_3'(t)| dt
      &= 2\pi \int_{c}^{2\pi} \abs{\sin\frac{1}{t} - \frac{1}{t}\cos\frac{1}{t}} dt \\
      &\geq 2\pi \int_{c}^{2\pi} \abs{\frac{1}{t}\cos\frac{1}{t}} - 1 dt \\
      &= 2\pi \int_{c}^{2\pi} \abs{\frac{1}{t}\cos\frac{1}{t}} dt - 4\pi^2.
    \end{align*}

    \item[(c)]
    For any integer $n > 0$, we have
    \begin{align*}
      &\int_{\left(2n\pi + \frac{\pi}{3}\right)^{-1}}^{\left(2n\pi - \frac{\pi}{3}\right)^{-1}}
        \abs{\frac{1}{t}\cos\frac{1}{t}} dt \\
      \geq&
      \int_{\left(2n\pi + \frac{\pi}{3}\right)^{-1}}^{\left(2n\pi - \frac{\pi}{3}\right)^{-1}}
         \left(2n\pi - \frac{\pi}{3}\right) \cdot \frac{1}{2} dt \\
      =&
      \left[ \left(2n\pi - \frac{\pi}{3}\right)^{-1}
        - \left(2n\pi + \frac{\pi}{3}\right)^{-1} \right]
        \cdot \left(2n\pi - \frac{\pi}{3}\right) \cdot \frac{1}{2} \\
      =&
      \frac{\frac{\pi}{3}}{2n\pi + \frac{\pi}{3}} \\
      >&
      \frac{1}{6} \cdot \frac{1}{n+1}
    \end{align*}
    since both
    $t \mapsto \frac{1}{t} \geq 2n\pi - \frac{\pi}{3}$
    and
    $t \mapsto \cos t \geq \frac{1}{2}$ on
    $\left[\left(2n\pi + \frac{\pi}{3}\right)^{-1}, \left(2n\pi - \frac{\pi}{3}\right)^{-1} \right]$.

    \item[(d)]
    As $c \geq \frac{1}{2N\pi - \frac{\pi}{3}}$ for some integer $N$,
    by (b)(c) we have
    \begin{align*}
      \int_{c}^{2\pi} |\gamma_3'(t)| dt
      &\geq
      2\pi \int_{c}^{2\pi} \abs{\frac{1}{t}\cos\frac{1}{t}} dt - 4\pi^2 \\
      &\geq
      2\pi \sum_{n=1}^{n=N}
        \int_{\left(2n\pi + \frac{\pi}{3}\right)^{-1}}^{\left(2n\pi - \frac{\pi}{3}\right)^{-1}}
          \abs{\frac{1}{t}\cos\frac{1}{t}} dt - 4\pi^2 \\
      &\geq
      2\pi \sum_{n=1}^{n=N}
        \frac{1}{6} \cdot \frac{1}{n+1} - 4\pi^2 \\
      &=
      \frac{\pi}{3} \sum_{n=1}^{n=N} \frac{1}{n+1} - 4\pi^2.
    \end{align*}

    \item[(e)]
    Hence
    \[
      \Lambda(\gamma_3)
      \geq
      \Lambda_{\left[\left(2N\pi - \frac{\pi}{3}\right)^{-1},2\pi\right]}(\gamma_3)
      \geq
      \frac{\pi}{3} \sum_{n=1}^{n=N} \frac{1}{n+1} - 4\pi^2.
    \]
    Let $N \to \infty$, and thus $\Lambda(\gamma_3)$ cannot be bounded (Theorem 3.28).
  \end{enumerate}
\end{enumerate}
$\Box$ \\\\



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\textbf{Exercise 6.19.}
\emph{Let $\gamma_1$ be a curve in $\mathbb{R}^k$, defined on $[a,b]$;
let $\phi$ be a continuous $1$-$1$ mapping of $[c,d]$ onto $[a,b]$, such that
$\phi(c) = a$; and define $\gamma_2(s) = \gamma_1(\phi(s))$.
Prove that $\gamma_2$ is an arc, a closed curve, or a rectifiable curve
if and only if the same is true of $\gamma_1$.
Prove that $\gamma_2$ and $\gamma_1$ have the same length.} \\

\emph{Proof.}
\begin{enumerate}
  \item[(1)]
  \emph{Show that $\phi$ is strictly monotonic.}
  Similar to Exercise 4.15.
  \begin{enumerate}
    \item[(a)]
    (Reductio ad absurdum)
    If $\phi$ were not strictly monotonic,
    then there exist $a < c < b \in \mathbb{R}^1$ such that
    \[
      \phi(a) \leq \phi(c) \geq \phi(b)
    \]
    or
    \[
      \phi(a) \geq \phi(c) \leq \phi(b).
    \]
    Since $\phi$ is one-to-one, all equalities does not hold.
    Hence
    \[
      \phi(a) < \phi(c) > \phi(b)
    \]
    or
    \[
      \phi(a) > \phi(c) < \phi(b).
    \]

    \item[(b)]
    The case $\phi(a) < \phi(c) > \phi(b)$.
    Take
    \[
      t = \frac{\max\{\phi(a),\phi(b)\} + \phi(c)}{2}
    \]
    so that $\phi(c) > t > \phi(a)$ and $\phi(c) > t > \phi(b)$.
    By Theorem 4.23 there exist $\xi_1 \in (a,c)$ and $\xi_2 \in(c,b)$
    such that $\phi(\xi_1) = \phi(\xi_2) = t$.
    Here $\xi_1 \neq \xi_2$, contrary to the injectivity of $\phi$.

    \item[(c)]
    The case $\phi(a) > \phi(c) < \phi(b)$.
    The proof is similar to (b).

    \item[(d)]
    By (b)(c), $\phi$ is strictly monotonic.
  \end{enumerate}

  \item[(2)]
  $\phi(d) = b$
  since $\phi$ is strictly monotonic (by (1)), surjective and $\phi(c) = a$.

  \item[(3)]
  The inverse mapping $\phi^{-1}$ is a continuous and injective mapping of $[a,b]$ onto $[c,d]$
  since $\phi$ is continuous and injective on a compact set $[c,d]$ (Theorem 4.17).

  \item[(4)]
  \emph{Show that $\gamma_2$ is an arc if and only if $\gamma_1$ is an arc.}
  Note the the composition of two injective maps is injective.
  Hence the result is established since
  $\gamma_2 = \gamma_1 \circ \phi$ and $\gamma_1 = \gamma_2 \circ \phi^{-1}$.

  \item[(5)]
  \emph{Show that $\gamma_2$ is a closed curve if and only if $\gamma_1$ is a closed curve.}
  Since $\gamma_2 = \gamma_1 \circ \phi$ and $\gamma_1 = \gamma_2 \circ \phi^{-1}$
  (as in (4)),
  $\gamma_1(a) = \gamma_1(b)$ if and only if $\gamma_2(c) = \gamma_2(d)$.

  \item[(6)]
  \emph{Show that $\gamma_2$ is a rectifiable curve if and only if
  $\gamma_1$ is a rectifiable curve.}
  Given any partition $P_1 = \{x_0, \ldots, x_n\}$ of $[a,b]$,
  there is a corresponding partition
  $P_2 = \{ \phi^{-1}(x_0), \ldots, \phi^{-1}(x_n) \}$ of $[c,d]$,
  and vice versa.
  (Given a partition $P_2 = \{x_0, \ldots, x_n\}$ of $[c,d]$,
  there is a corresponding partition
  $P_1 = \{ \phi(x_0), \ldots, \phi(x_n) \}$ of $[a,b]$.)
  Again, since $\gamma_2 = \gamma_1 \circ \phi$ and $\gamma_1 = \gamma_2 \circ \phi^{-1}$
  (as in (4)),
  \[
    \Lambda(P_1, \gamma_1) = \Lambda(P_2, \gamma_2).
  \]
  Hence $\gamma_2$ is rectifiable if and only if $\gamma_1$ is rectifiable.

  \item[(7)]
  \emph{Show that $\gamma_2$ and $\gamma_1$ have the same length.}
  Take the supremum over all partitions $P_1$ of $[a,b]$ to get
  \[
    \Lambda(P_1, \gamma_1) = \Lambda(P_2, \gamma_2) \leq \Lambda(\gamma_1).
  \]
  Hence $\Lambda(\gamma_1)$ is an upper of $\Lambda(P_2, \gamma_2)$.
  So
  \[
    \Lambda(\gamma_2) \leq \Lambda(\gamma_1).
  \]
  Similarly, $\Lambda(\gamma_1) \leq \Lambda(\gamma_2)$.
  Therefore $\Lambda(\gamma_1) = \Lambda(\gamma_2)$
  (whether $\Lambda(\gamma_1)$ or $\Lambda(\gamma_2)$ is finite or not).
\end{enumerate}
$\Box$ \\\\



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\end{document}